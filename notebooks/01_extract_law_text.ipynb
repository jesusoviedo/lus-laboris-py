{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad38a4e-4836-417b-9f58-3a566961f189",
   "metadata": {},
   "source": [
    "# Downloading the Law HTML Page / Descargando la página HTML de la ley\n",
    "\n",
    "**Goal**: Download the Paraguay Labor Code HTML page and save it locally for further processing.  \n",
    "\n",
    "**Input**: The URL of the law page on the official government website.  \n",
    "\n",
    "**Approach**:  \n",
    "- Use the `requests` library to perform an HTTP GET request.  \n",
    "- Ensure the request is successful and handle possible errors.  \n",
    "- Create the target folder if it does not exist.  \n",
    "- Save the HTML content to a file at `../data/raw/codigo_trabajo_py.html`.\n",
    "\n",
    "**Output**: Local HTML file containing the law text.  \n",
    "\n",
    "**Why this matters**: Having a local copy ensures consistent processing and avoids repeated web requests, which is especially useful for parsing, indexing, or text analysis tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo**: Descargar la página HTML del Código Laboral de Paraguay y guardarla localmente para su posterior procesamiento.  \n",
    "\n",
    "**Entrada**: URL de la página de la ley en el sitio oficial del gobierno.  \n",
    "\n",
    "**Enfoque**:  \n",
    "- Usar la librería `requests` para hacer una petición HTTP GET.  \n",
    "- Verificar que la petición sea exitosa y manejar posibles errores.  \n",
    "- Crear la carpeta de destino si no existe.  \n",
    "- Guardar el contenido HTML en un archivo en `../data/raw/codigo_trabajo_py.html`.\n",
    "\n",
    "**Salida**: Archivo HTML local que contiene el texto de la ley.  \n",
    "\n",
    "**Por qué importa**: Tener una copia local garantiza un procesamiento consistente y evita solicitudes web repetidas, útil para parsing, indexación o análisis de texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7f5989-0929-47bb-b755-6b5a585b6587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Página descargada y guardada en: ../data/raw/codigo_trabajo_py.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_law_page(url, output_path=\"../data/raw/codigo_trabajo_py.html\"):\n",
    "    out_path = Path(output_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Lanza excepción si hay error en la descarga\n",
    "\n",
    "    # Guardar contenido en archivo\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "\n",
    "url = \"https://www.bacn.gov.py/leyes-paraguayas/2608/ley-n-213-establece-el-codigo-del-trabajo\"\n",
    "download_law_page(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c266d32e",
   "metadata": {},
   "source": [
    "# Transformation of downloaded data / Transformación de los datos descargados\n",
    "\n",
    "**Goal**: Extract the Paraguay Labor Code text from a local HTML file (`../data/raw/codigo_trabajo_py.html`) for further processing, such as cleaning, indexing, or search.  \n",
    "\n",
    "**Input**: Local HTML file saved from the source website.  \n",
    "\n",
    "**Approach**:  \n",
    "- Open the file using a context manager with the selected encoding.  \n",
    "- Parse the HTML with BeautifulSoup using the built-in `html.parser`.  \n",
    "- Locate the main container `<div class=\"entry-content\">`.  \n",
    "- Extract the text while preserving line breaks.\n",
    "\n",
    "**Output**: Clean plain text in memory.  \n",
    "\n",
    "**Why this matters**: Ensures that the extracted text is complete and readable, making it suitable for downstream tasks like indexing, search, or QA.\n",
    "\n",
    "**File path and encoding**\n",
    "\n",
    "**Path**: `../data/raw/codigo_trabajo_py.html`. Adjust if your working directory changes.  \n",
    "\n",
    "**Encoding**: The file is likely in Latin-1 (`encoding='latin-1'`). If you notice encoding artifacts such as `Ã³`, try `utf-8` or `cp1252`.  \n",
    "\n",
    "**Reading the HTML**\n",
    "\n",
    "Use a context manager to safely open and read the file.  \n",
    "\n",
    "**Common pitfalls**:  \n",
    "- FileNotFoundError if the path is wrong.  \n",
    "- UnicodeDecodeError if the encoding does not match the file.\n",
    "\n",
    "**Parse and select content**\n",
    "\n",
    "**Parser**: `html.parser` is built-in and sufficient for this HTML.  \n",
    "\n",
    "**Target container**: The law text is inside `<div class=\"entry-content\">`, selected with `soup.find('div', class_='entry-content')`.  \n",
    "\n",
    "**Fallbacks**: If `None` is returned, inspect the DOM for alternative classes or IDs.\n",
    "\n",
    "**Extract text cleanly**\n",
    "\n",
    "Use `get_text(separator='\\n', strip=True)` to flatten the HTML while preserving line breaks.  \n",
    "\n",
    "**Tips**: Adjust `separator` for paragraph spacing or post-process the text to normalize multiple newlines or bullet points.\n",
    "\n",
    "---\n",
    "\n",
    "**Objetivo**: Extraer el texto del Código Laboral de Paraguay desde un archivo HTML local (`../data/raw/codigo_trabajo_py.html`) para procesamiento posterior, como limpieza, indexación o búsqueda.  \n",
    "\n",
    "**Entrada**: Archivo HTML local guardado desde el sitio de origen.  \n",
    "\n",
    "**Enfoque**:  \n",
    "- Abrir el archivo con un gestor de contexto usando la codificación correcta.  \n",
    "- Parsear el HTML con BeautifulSoup (`html.parser`).  \n",
    "- Localizar el contenedor principal `<div class=\"entry-content\">`.  \n",
    "- Extraer el texto preservando los saltos de línea.\n",
    "\n",
    "**Salida**: Texto plano limpio en memoria.  \n",
    "\n",
    "**Por qué importa**: Garantiza que el texto extraído esté completo y sea legible, apto para tareas posteriores como indexación, búsqueda o QA.\n",
    "\n",
    "**Ruta y codificación**\n",
    "\n",
    "**Ruta**: `../data/raw/codigo_trabajo_py.html`. Ajusta si cambia tu directorio de trabajo.  \n",
    "\n",
    "**Codificación**: Probablemente el archivo está en Latin-1 (`encoding='latin-1'`). Si aparecen artefactos como `Ã³`, prueba con `utf-8` o `cp1252`.\n",
    "\n",
    "**Lectura del HTML**\n",
    "\n",
    "Usa un gestor de contexto para abrir y leer el archivo de forma segura.  \n",
    "\n",
    "**Errores comunes**:  \n",
    "- FileNotFoundError si la ruta es incorrecta.  \n",
    "- UnicodeDecodeError si la codificación no coincide con el archivo.\n",
    "\n",
    "**Parseo y selección de contenido**\n",
    "\n",
    "**Parser**: `html.parser` es integrado y suficiente para este HTML.  \n",
    "\n",
    "**Contenedor objetivo**: El texto de la ley está dentro de `<div class=\"entry-content\">`, seleccionado con `soup.find('div', class_='entry-content')`.  \n",
    "**Alternativas**: Si retorna `None`, inspecciona el DOM para otras clases o IDs posibles.\n",
    "\n",
    "**Extracción de texto limpio**\n",
    "\n",
    "Usa `get_text(separator='\\n', strip=True)` para aplanar el HTML preservando los saltos de línea.  \n",
    "\n",
    "**Consejos**: Ajusta `separator` para espaciar párrafos o post-procesa el texto para normalizar saltos de línea múltiples o viñetas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eec1144-b275-4470-a7ea-1b5cdf2d660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from ftfy import fix_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80fc327e-667b-497b-8a3a-d50b5d86a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_archivo_html = \"../data/raw/codigo_trabajo_py.html\"\n",
    "\n",
    "with open(nombre_archivo_html, encoding=\"latin-1\") as archivo:\n",
    "    contenido_html = archivo.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d9a6e4-c2d0-4229-9b5f-1321119ac780",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(contenido_html, \"html.parser\")\n",
    "contenido_ley = soup.find(\"div\", class_=\"entry-content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458873e2-e9b6-4ec9-b803-6a4a1e63f7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Contenido de la Ley extraído exitosamente ---\n"
     ]
    }
   ],
   "source": [
    "if contenido_ley:\n",
    "    texto_limpio = contenido_ley.get_text(separator=\"\\n\", strip=True)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9bbd9b-0830-49d9-a396-73fe71157116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(texto_limpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6140f33-684d-4446-8f2e-4cd90e706df9",
   "metadata": {},
   "source": [
    "# Header and Article Patterns / Patrones de Encabezados y Artículos\n",
    "\n",
    "This section defines regular expressions and mappings to identify different parts of the legal text:\n",
    "\n",
    "- `HEADER_PATTERNS`: A dictionary containing regex patterns for:\n",
    "  - `'libro'`: Matches \"LIBRO\" followed by its name (e.g., \"LIBRO PRIMERO\").\n",
    "  - `'titulo'`: Matches \"TITULO\" followed by its name (e.g., \"TITULO PRIMERO\").\n",
    "  - `'capitulo'`: Matches \"CAPITULO\" followed by Roman numerals (e.g., \"CAPITULO I\").\n",
    "  \n",
    "- `ARTICULO_PATTERN`: A regex to detect article headers like \"Artículo 1°.-\".\n",
    "\n",
    "- `ROMAN_MAP`: Maps Spanish ordinal words to integer numbers for easy conversion (e.g., \"PRIMERO\" → 1).\n",
    "\n",
    "---\n",
    "\n",
    "Esta sección define expresiones regulares y mapeos para identificar diferentes partes del texto legal:\n",
    "\n",
    "- `HEADER_PATTERNS`: Un diccionario con patrones regex para:\n",
    "  - `'libro'`: Detecta \"LIBRO\" seguido de su nombre (ej.: \"LIBRO PRIMERO\").\n",
    "  - `'titulo'`: Detecta \"TITULO\" seguido de su nombre (ej.: \"TITULO PRIMERO\").\n",
    "  - `'capitulo'`: Detecta \"CAPITULO\" seguido de números romanos (ej.: \"CAPITULO I\").\n",
    "  \n",
    "- `ARTICULO_PATTERN`: Regex para detectar encabezados de artículos como \"Artículo 1°.-\".\n",
    "\n",
    "- `ROMAN_MAP`: Mapea palabras ordinales en español a números enteros para facilitar la conversión (ej.: \"PRIMERO\" → 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81739ab9-d8ab-4315-8c79-453d6ad5f89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_PATTERNS = {\n",
    "    \"libro\": re.compile(r\"^LIBRO\\s+([A-ZÁÉÍÓÚÑ]+)\\s*$\", re.IGNORECASE),\n",
    "    \"titulo\": re.compile(r\"^TITULO\\s+([A-ZÁÉÍÓÚÑ]+)\\s*$\", re.IGNORECASE),\n",
    "    \"capitulo\": re.compile(r\"^CAPITULO\\s+([IVXLCDM]+)\\s*$\", re.IGNORECASE),\n",
    "}\n",
    "\n",
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-\\s*$\", re.IGNORECASE)\n",
    "\n",
    "ROMAN_MAP = {\n",
    "    \"PRIMERO\": 1,\n",
    "    \"SEGUNDO\": 2,\n",
    "    \"TERCERO\": 3,\n",
    "    \"CUARTO\": 4,\n",
    "    \"QUINTO\": 5,\n",
    "    \"SEXTO\": 6,\n",
    "    \"SÉPTIMO\": 7,\n",
    "    \"SEPTIMO\": 7,\n",
    "    \"OCTAVO\": 8,\n",
    "    \"NOVENO\": 9,\n",
    "    \"DÉCIMO\": 10,\n",
    "    \"DECIMO\": 10,\n",
    "    \"UNDÉCIMO\": 11,\n",
    "    \"UNDECIMO\": 11,\n",
    "    \"DUODÉCIMO\": 12,\n",
    "    \"DUODECIMO\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb30185-977b-425b-ad89-5281cf34bc18",
   "metadata": {},
   "source": [
    "# Roman Numeral Conversion / Conversión de Números Romanos\n",
    "\n",
    "This section defines a helper function to convert Roman numerals into integers:\n",
    "\n",
    "- `_ROMAN_VALUES`: A dictionary mapping Roman numeral characters to their integer values.\n",
    "- `roman_to_int(roman)`: Converts a Roman numeral string into an integer.\n",
    "  - The function iterates over the characters in reverse.\n",
    "  - If a smaller value precedes a larger one, it is subtracted.\n",
    "  - Otherwise, the value is added.\n",
    "\n",
    "---\n",
    "\n",
    "Esta sección define una función auxiliar para convertir números romanos en enteros:\n",
    "\n",
    "- `_ROMAN_VALUES`: Un diccionario que asigna valores enteros a los caracteres de números romanos.\n",
    "- `roman_to_int(roman)`: Convierte una cadena de número romano a un número entero.\n",
    "  - La función itera sobre los caracteres en orden inverso.\n",
    "  - Si un valor menor precede a un valor mayor, se resta.\n",
    "  - De lo contrario, se suma el valor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "313789e1-bab6-441b-a8dc-8acf430ae8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ROMAN_VALUES = {\"I\": 1, \"V\": 5, \"X\": 10, \"L\": 50, \"C\": 100, \"D\": 500, \"M\": 1000}\n",
    "\n",
    "\n",
    "def roman_to_int(roman):\n",
    "    roman = roman.strip().upper()\n",
    "    total = 0\n",
    "    prev = 0\n",
    "    for ch in reversed(roman):\n",
    "        val = _ROMAN_VALUES.get(ch, 0)\n",
    "        if val < prev:\n",
    "            total -= val\n",
    "        else:\n",
    "            total += val\n",
    "            prev = val\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d9123-d81c-4bbb-86b3-e75233853baa",
   "metadata": {},
   "source": [
    "# Metadata Extraction / Extracción de Metadatos\n",
    "\n",
    "This function extracts key metadata from the legal text header, before the first chapter:\n",
    "\n",
    "- `extract_metadata(lines)`: Receives a list of text lines.\n",
    "  - Constructs the `encabezado` (header) until the first \"CAPÍTULO I\".\n",
    "  - Searches within this header for:\n",
    "    - Law number (`numero_ley`) using a regex that matches \"LEY N° ...\".\n",
    "    - Promulgation date (`fecha_promulgacion`) using a regex for \"Fecha de Promulgación\".\n",
    "    - Publication date (`fecha_publicacion`) using a regex for \"Fecha de Publicación\".\n",
    "  - Returns a dictionary `meta` containing these values.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función extrae metadatos clave del encabezado del texto legal, antes del primer capítulo:\n",
    "\n",
    "- `extract_metadata(lines)`: Recibe una lista de líneas de texto.\n",
    "  - Construye el `encabezado` hasta el primer \"CAPÍTULO I\".\n",
    "  - Busca dentro de este encabezado:\n",
    "    - Número de ley (`numero_ley`) usando una expresión regular que detecta \"LEY N° ...\".\n",
    "    - Fecha de promulgación (`fecha_promulgacion`) usando regex para \"Fecha de Promulgación\".\n",
    "    - Fecha de publicación (`fecha_publicacion`) usando regex para \"Fecha de Publicación\".\n",
    "  - Devuelve un diccionario `meta` con estos valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d630ebe-6e8e-4d07-9c75-eee7ee0a5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(lines):\n",
    "    \"\"\"Extrae número de ley y fechas desde el encabezado (antes del primer CAPITULO I).\"\"\"\n",
    "    meta = {}\n",
    "\n",
    "    encabezado = []\n",
    "    for ln in lines:\n",
    "        if re.match(r\"CAP[IÍ]TULO\\s+I\\b\", ln, re.IGNORECASE):\n",
    "            break\n",
    "        encabezado.append(ln)\n",
    "\n",
    "    encabezado_text = \" \".join(encabezado)\n",
    "\n",
    "    ley_match = re.search(r\"LEY\\s*N[°º]?\\s*(\\d+)\", encabezado_text, re.IGNORECASE)\n",
    "    if ley_match:\n",
    "        meta[\"numero_ley\"] = ley_match.group(1)\n",
    "\n",
    "    promulg_match = re.search(\n",
    "        r\"Fecha\\s+de\\s+Promulgaci[oó]n:?\\s*(\\d{2}-\\d{2}-\\d{4})\", encabezado_text, re.IGNORECASE\n",
    "    )\n",
    "    if promulg_match:\n",
    "        meta[\"fecha_promulgacion\"] = promulg_match.group(1)\n",
    "\n",
    "    public_match = re.search(\n",
    "        r\"Fecha\\s+de\\s+Publicaci[oó]n:?\\s*(\\d{2}-\\d{2}-\\d{4})\", encabezado_text, re.IGNORECASE\n",
    "    )\n",
    "    if public_match:\n",
    "        meta[\"fecha_publicacion\"] = public_match.group(1)\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae11fc-bd55-4cef-bbec-5f2529ce779d",
   "metadata": {},
   "source": [
    "# Article Extraction / Extracción de Artículos\n",
    "\n",
    "This function segments the legal text into structured parts: books, titles, chapters, and articles in detail.\n",
    "\n",
    "- `extract_articles(lines)`: Receives a list of text lines.\n",
    "  - Maintains context variables for the current book, title, chapter, and chapter description.\n",
    "  - Uses the helper function `flush_article()` to finalize and store the current article when a new header or article starts.\n",
    "  - Iterates through the lines:\n",
    "    - Detects **LIBRO** headers using `HEADER_PATTERNS['libro']`.\n",
    "    - Detects **TITULO** headers using `HEADER_PATTERNS['titulo']`.\n",
    "    - Detects **CAPITULO** headers and optionally captures the next line as chapter description.\n",
    "    - Detects article headers using `ARTICULO_PATTERN` and accumulates the article text until the next header or article.\n",
    "  - Returns a list of dictionaries, each representing an article with metadata and cleaned text.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función segmenta el texto legal en partes estructuradas: libros, títulos, capítulos y artículos en detalle.\n",
    "\n",
    "- `extract_articles(lines)`: Recibe una lista de líneas de texto.\n",
    "  - Mantiene variables de contexto para el libro, título, capítulo y descripción del capítulo actual.\n",
    "  - Utiliza la función auxiliar `flush_article()` para finalizar y almacenar el artículo actual cuando empieza un nuevo encabezado o artículo.\n",
    "  - Itera sobre las líneas:\n",
    "    - Detecta encabezados de **LIBRO** con `HEADER_PATTERNS['libro']`.\n",
    "    - Detecta encabezados de **TITULO** con `HEADER_PATTERNS['titulo']`.\n",
    "    - Detecta encabezados de **CAPITULO** y opcionalmente captura la siguiente línea como descripción del capítulo.\n",
    "    - Detecta encabezados de artículo con `ARTICULO_PATTERN` y acumula el texto del artículo hasta el siguiente encabezado o artículo.\n",
    "  - Devuelve una lista de diccionarios, cada uno representando un artículo con sus metadatos y texto limpio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98f02ae9-3a21-4447-849d-3edefa82a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_articles(lines):\n",
    "    \"\"\"Segmenta libros, títulos, capítulos y artículos en detalle.\"\"\"\n",
    "    # Contexto de encabezados\n",
    "    current_libro = None\n",
    "    current_libro_num = None\n",
    "    current_titulo = None\n",
    "    current_capitulo = None\n",
    "    current_capitulo_num = None\n",
    "    current_capitulo_desc = None\n",
    "\n",
    "    # Segmentación de artículos\n",
    "    articles = []\n",
    "    current_article_num = None\n",
    "    current_article_lines = []\n",
    "\n",
    "    def flush_article():\n",
    "        if current_article_num is None:\n",
    "            return\n",
    "        body = \"\\n\".join(current_article_lines).strip()\n",
    "        articles.append(\n",
    "            {\n",
    "                \"articulo_numero\": int(current_article_num),\n",
    "                \"libro\": current_libro.lower() if current_libro else None,\n",
    "                \"libro_numero\": current_libro_num,\n",
    "                \"titulo\": current_titulo.lower() if current_titulo else None,\n",
    "                \"capitulo\": current_capitulo.lower() if current_capitulo else None,\n",
    "                \"capitulo_numero\": current_capitulo_num,\n",
    "                \"capitulo_descripcion\": current_capitulo_desc.lower()\n",
    "                if current_capitulo_desc\n",
    "                else None,\n",
    "                \"articulo\": body.lower().replace(\"\\n\", \"\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        ln = lines[i]\n",
    "\n",
    "        # Detectar LIBRO\n",
    "        m_lib = HEADER_PATTERNS[\"libro\"].match(ln)\n",
    "        if m_lib:\n",
    "            current_libro = f\"LIBRO {m_lib.group(1).title()}\"\n",
    "            current_libro_num = ROMAN_MAP.get(m_lib.group(1).upper())\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detectar TITULO\n",
    "        m_tit = HEADER_PATTERNS[\"titulo\"].match(ln)\n",
    "        if m_tit:\n",
    "            current_titulo = f\"TITULO {m_tit.group(1).title()}\"\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detectar CAPITULO\n",
    "        m_cap = HEADER_PATTERNS[\"capitulo\"].match(ln)\n",
    "        if m_cap:\n",
    "            roman = m_cap.group(1)\n",
    "            current_capitulo = f\"CAPITULO {roman}\"\n",
    "            current_capitulo_num = roman_to_int(roman)\n",
    "            next_desc = None\n",
    "            if i + 1 < len(lines):\n",
    "                nxt = lines[i + 1]\n",
    "                if not (\n",
    "                    HEADER_PATTERNS[\"libro\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"titulo\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"capitulo\"].match(nxt)\n",
    "                    or ARTICULO_PATTERN.match(nxt)\n",
    "                ):\n",
    "                    next_desc = nxt\n",
    "            current_capitulo_desc = next_desc\n",
    "            i += 2 if next_desc else 1\n",
    "            continue\n",
    "\n",
    "        # Detectar inicio de Artículo\n",
    "        m_art = ARTICULO_PATTERN.match(ln)\n",
    "        if m_art:\n",
    "            flush_article()\n",
    "            current_article_num = m_art.group(1)\n",
    "            current_article_lines = []\n",
    "            i += 1\n",
    "            while i < len(lines):\n",
    "                nxt = lines[i]\n",
    "                if (\n",
    "                    HEADER_PATTERNS[\"libro\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"titulo\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"capitulo\"].match(nxt)\n",
    "                    or ARTICULO_PATTERN.match(nxt)\n",
    "                ):\n",
    "                    break\n",
    "                current_article_lines.append(nxt)\n",
    "                i += 1\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    flush_article()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb1abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_processed_data(articles):\n",
    "    \"\"\"Valida la integridad y calidad de los datos procesados.\"\"\"\n",
    "    validation_results = {\n",
    "        \"total_articles\": len(articles),\n",
    "        \"valid_articles\": 0,\n",
    "        \"invalid_articles\": [],\n",
    "        \"missing_fields\": [],\n",
    "        \"quality_score\": 0.0,\n",
    "    }\n",
    "\n",
    "    required_fields = [\"articulo_numero\", \"libro\", \"capitulo\", \"articulo\"]\n",
    "\n",
    "    for article in articles:\n",
    "        article_valid = True\n",
    "        article_issues = []\n",
    "\n",
    "        # Verificar campos requeridos\n",
    "        for field in required_fields:\n",
    "            if field not in article or not article[field]:\n",
    "                article_issues.append(f\"Campo faltante: {field}\")\n",
    "                article_valid = False\n",
    "\n",
    "        # Verificar que el número de artículo sea válido\n",
    "        if \"articulo_numero\" in article:\n",
    "            art_num = article[\"articulo_numero\"]\n",
    "            if not isinstance(art_num, int) or art_num < 1 or art_num > 413:\n",
    "                article_issues.append(f\"Número de artículo inválido: {art_num}\")\n",
    "                article_valid = False\n",
    "\n",
    "        # Verificar que el contenido no esté vacío\n",
    "        if \"articulo\" in article and len(article[\"articulo\"].strip()) < 10:\n",
    "            article_issues.append(\"Contenido del artículo demasiado corto\")\n",
    "            article_valid = False\n",
    "\n",
    "        if article_valid:\n",
    "            validation_results[\"valid_articles\"] += 1\n",
    "        else:\n",
    "            validation_results[\"invalid_articles\"].append(\n",
    "                {\n",
    "                    \"articulo_numero\": article.get(\"articulo_numero\", \"desconocido\"),\n",
    "                    \"issues\": article_issues,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Calcular score de calidad\n",
    "    validation_results[\"quality_score\"] = (\n",
    "        validation_results[\"valid_articles\"] / validation_results[\"total_articles\"]\n",
    "    )\n",
    "\n",
    "    return validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f31e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_completeness(articles):\n",
    "    \"\"\"Verifica que todos los artículos esperados estén presentes.\"\"\"\n",
    "\n",
    "    article_numbers = [art[\"articulo_numero\"] for art in articles if \"articulo_numero\" in art]\n",
    "\n",
    "    # Verificar rango completo (1-413)\n",
    "    expected_range = set(range(1, 414))\n",
    "    found_numbers = set(article_numbers)\n",
    "\n",
    "    missing_articles = expected_range - found_numbers\n",
    "    duplicate_articles = [num for num in article_numbers if article_numbers.count(num) > 1]\n",
    "\n",
    "    completeness_report = {\n",
    "        \"expected_total\": 413,\n",
    "        \"found_total\": len(found_numbers),\n",
    "        \"missing_articles\": sorted(list(missing_articles)),\n",
    "        \"duplicate_articles\": duplicate_articles,\n",
    "        \"completeness_percentage\": len(found_numbers) / 413 * 100,\n",
    "    }\n",
    "\n",
    "    if missing_articles:\n",
    "        pass\n",
    "\n",
    "    if duplicate_articles:\n",
    "        pass\n",
    "\n",
    "    return completeness_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f78c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_content_quality(articles):\n",
    "    \"\"\"Analiza la calidad del contenido extraído.\"\"\"\n",
    "    quality_metrics = {\n",
    "        \"avg_content_length\": 0,\n",
    "        \"short_articles\": 0,  # < 50 caracteres\n",
    "        \"medium_articles\": 0,  # 50-200 caracteres\n",
    "        \"long_articles\": 0,  # > 200 caracteres\n",
    "        \"articles_with_special_chars\": 0,\n",
    "        \"articles_with_numbers\": 0,\n",
    "    }\n",
    "\n",
    "    content_lengths = []\n",
    "\n",
    "    for article in articles:\n",
    "        if \"articulo\" not in article:\n",
    "            continue\n",
    "\n",
    "        content = article[\"articulo\"]\n",
    "        content_length = len(content.strip())\n",
    "        content_lengths.append(content_length)\n",
    "\n",
    "        # Clasificar por longitud\n",
    "        if content_length < 50:\n",
    "            quality_metrics[\"short_articles\"] += 1\n",
    "        elif content_length <= 200:\n",
    "            quality_metrics[\"medium_articles\"] += 1\n",
    "        else:\n",
    "            quality_metrics[\"long_articles\"] += 1\n",
    "\n",
    "        # Verificar características especiales\n",
    "        if any(char in content for char in [\"°\", \"º\", \"§\", \"¶\"]):\n",
    "            quality_metrics[\"articles_with_special_chars\"] += 1\n",
    "\n",
    "        if any(char.isdigit() for char in content):\n",
    "            quality_metrics[\"articles_with_numbers\"] += 1\n",
    "\n",
    "    if content_lengths:\n",
    "        quality_metrics[\"avg_content_length\"] = sum(content_lengths) / len(content_lengths)\n",
    "\n",
    "    return quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a00bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(articles):\n",
    "    \"\"\"Genera un reporte completo de calidad de datos.\"\"\"\n",
    "    validation_results = validate_processed_data(articles)\n",
    "    completeness_report = verify_data_completeness(articles)\n",
    "    quality_metrics = analyze_content_quality(articles)\n",
    "\n",
    "    report = f\"\"\"\n",
    "📊 REPORTE DE CALIDAD DE DATOS PROCESADOS\n",
    "{\"=\" * 50}\n",
    "\n",
    "✅ VALIDACIÓN DE ESTRUCTURA:\n",
    "   • Artículos válidos: {validation_results[\"valid_articles\"]}/{validation_results[\"total_articles\"]}\n",
    "   • Score de calidad: {validation_results[\"quality_score\"]:.2%}\n",
    "   • Artículos con problemas: {len(validation_results[\"invalid_articles\"])}\n",
    "\n",
    "📋 COMPLETITUD DE DATOS:\n",
    "   • Artículos encontrados: {completeness_report[\"found_total\"]}/413\n",
    "   • Completitud: {completeness_report[\"completeness_percentage\"]:.1f}%\n",
    "   • Artículos faltantes: {len(completeness_report[\"missing_articles\"])}\n",
    "   • Artículos duplicados: {len(completeness_report[\"duplicate_articles\"])}\n",
    "\n",
    "📝 ANÁLISIS DE CONTENIDO:\n",
    "   • Longitud promedio: {quality_metrics[\"avg_content_length\"]:.1f} caracteres\n",
    "   • Artículos cortos (< 50 chars): {quality_metrics[\"short_articles\"]}\n",
    "   • Artículos medianos (50-200 chars): {quality_metrics[\"medium_articles\"]}\n",
    "   • Artículos largos (> 200 chars): {quality_metrics[\"long_articles\"]}\n",
    "   • Con caracteres especiales: {quality_metrics[\"articles_with_special_chars\"]}\n",
    "   • Con números: {quality_metrics[\"articles_with_numbers\"]}\n",
    "\n",
    "🎯 ESTADO GENERAL: {\"✅ EXCELENTE\" if validation_results[\"quality_score\"] > 0.95 else \"⚠️ REQUIERE ATENCIÓN\"}\n",
    "\"\"\"\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fe3d70d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parsed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Generar reporte completo de calidad\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m quality_report = generate_quality_report(\u001b[43mparsed\u001b[49m[\u001b[33m'\u001b[39m\u001b[33marticulos\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(quality_report)\n",
      "\u001b[31mNameError\u001b[39m: name 'parsed' is not defined"
     ]
    }
   ],
   "source": [
    "# Generar reporte completo de calidad\n",
    "quality_report = generate_quality_report(parsed[\"articulos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ac855-1d97-49e3-8787-97c50de70c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_articles(lines):\n",
    "    \"\"\"Segmenta libros, títulos, capítulos y artículos en detalle.\"\"\"\n",
    "    # Contexto de encabezados\n",
    "    current_libro = None\n",
    "    current_libro_num = None\n",
    "    current_titulo = None\n",
    "    current_capitulo = None\n",
    "    current_capitulo_num = None\n",
    "    current_capitulo_desc = None\n",
    "\n",
    "    # Segmentación de artículos\n",
    "    articles = []\n",
    "    current_article_num = None\n",
    "    current_article_lines = []\n",
    "\n",
    "    def flush_article():\n",
    "        if current_article_num is None:\n",
    "            return\n",
    "        body = \"\\n\".join(current_article_lines).strip()\n",
    "        articles.append(\n",
    "            {\n",
    "                \"articulo_numero\": int(current_article_num),\n",
    "                \"libro\": current_libro.lower() if current_libro else None,\n",
    "                \"libro_numero\": current_libro_num,\n",
    "                \"titulo\": current_titulo.lower() if current_titulo else None,\n",
    "                \"capitulo\": current_capitulo.lower() if current_capitulo else None,\n",
    "                \"capitulo_numero\": current_capitulo_num,\n",
    "                \"capitulo_descripcion\": current_capitulo_desc.lower()\n",
    "                if current_capitulo_desc\n",
    "                else None,\n",
    "                \"articulo\": body.lower().replace(\"\\n\", \"\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        ln = lines[i]\n",
    "\n",
    "        # Detectar LIBRO\n",
    "        m_lib = HEADER_PATTERNS[\"libro\"].match(ln)\n",
    "        if m_lib:\n",
    "            current_libro = f\"LIBRO {m_lib.group(1).title()}\"\n",
    "            current_libro_num = ROMAN_MAP.get(m_lib.group(1).upper())\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detectar TITULO\n",
    "        m_tit = HEADER_PATTERNS[\"titulo\"].match(ln)\n",
    "        if m_tit:\n",
    "            current_titulo = f\"TITULO {m_tit.group(1).title()}\"\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # Detectar CAPITULO\n",
    "        m_cap = HEADER_PATTERNS[\"capitulo\"].match(ln)\n",
    "        if m_cap:\n",
    "            roman = m_cap.group(1)\n",
    "            current_capitulo = f\"CAPITULO {roman}\"\n",
    "            current_capitulo_num = roman_to_int(roman)\n",
    "            next_desc = None\n",
    "            if i + 1 < len(lines):\n",
    "                nxt = lines[i + 1]\n",
    "                if not (\n",
    "                    HEADER_PATTERNS[\"libro\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"titulo\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"capitulo\"].match(nxt)\n",
    "                    or ARTICULO_PATTERN.match(nxt)\n",
    "                ):\n",
    "                    next_desc = nxt\n",
    "            current_capitulo_desc = next_desc\n",
    "            i += 2 if next_desc else 1\n",
    "            continue\n",
    "\n",
    "        # Detectar inicio de Artículo\n",
    "        m_art = ARTICULO_PATTERN.match(ln)\n",
    "        if m_art:\n",
    "            flush_article()\n",
    "            current_article_num = m_art.group(1)\n",
    "            current_article_lines = []\n",
    "            i += 1\n",
    "            while i < len(lines):\n",
    "                nxt = lines[i]\n",
    "                if (\n",
    "                    HEADER_PATTERNS[\"libro\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"titulo\"].match(nxt)\n",
    "                    or HEADER_PATTERNS[\"capitulo\"].match(nxt)\n",
    "                    or ARTICULO_PATTERN.match(nxt)\n",
    "                ):\n",
    "                    break\n",
    "                current_article_lines.append(nxt)\n",
    "                i += 1\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    flush_article()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3402b24c-fdc8-4314-a7ce-e39e7fb4ff43",
   "metadata": {},
   "source": [
    "# Full Law Text Parsing / Parseo Completo del Texto Legal\n",
    "\n",
    "This function combines metadata extraction and article segmentation to parse the entire legal text:\n",
    "\n",
    "- `parse_law_text(raw_text)`: Receives the raw text of a law.\n",
    "  - Cleans the text using `fix_text()` to correct encoding issues.\n",
    "  - Splits the text into non-empty lines.\n",
    "  - Calls `extract_metadata(lines)` to extract law number, promulgation date, and publication date.\n",
    "  - Calls `extract_articles(lines)` to segment books, titles, chapters, and articles.\n",
    "  - Returns a dictionary containing `meta` (metadata) and `articulos` (list of structured articles).\n",
    "\n",
    "---\n",
    "\n",
    "Esta función combina la extracción de metadatos y la segmentación de artículos para parsear todo el texto legal:\n",
    "\n",
    "- `parse_law_text(raw_text)`: Recibe el texto bruto de una ley.\n",
    "  - Limpia el texto usando `fix_text()` para corregir problemas de codificación.\n",
    "  - Divide el texto en líneas no vacías.\n",
    "  - Llama a `extract_metadata(lines)` para extraer número de ley, fecha de promulgación y fecha de publicación.\n",
    "  - Llama a `extract_articles(lines)` para segmentar libros, títulos, capítulos y artículos.\n",
    "  - Devuelve un diccionario que contiene `meta` (metadatos) y `articulos` (lista de artículos estructurados).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc40704-7209-45db-9d9c-1e401c73bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_law_text(raw_text):\n",
    "    \"\"\"Parsea el texto completo en metadatos y artículos.\"\"\"\n",
    "    text = fix_text(raw_text)\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "\n",
    "    meta = extract_metadata(lines)\n",
    "    articles = extract_articles(lines)\n",
    "\n",
    "    return {\n",
    "        \"meta\": meta,\n",
    "        \"articulos\": articles,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba84f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse_law_text(texto_limpio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83a3366-5197-4068-9621-17cbfb529282",
   "metadata": {},
   "source": [
    "# Preview Parsed Data / Previsualización de Datos Parseados\n",
    "\n",
    "This code prints a preview of the parsed law data in JSON format:\n",
    "\n",
    "- Uses `json.dumps` to convert a dictionary into a formatted JSON string.\n",
    "- The dictionary contains:\n",
    "  - `meta`: The metadata of the law.\n",
    "  - `preview_articulos`: Only the first three articles for quick inspection.\n",
    "- `ensure_ascii=False` preserves special characters.\n",
    "- `indent=4` makes the JSON readable.\n",
    "\n",
    "---\n",
    "\n",
    "Este código imprime una previsualización de los datos parseados de la ley en formato JSON:\n",
    "\n",
    "- Usa `json.dumps` para convertir un diccionario en una cadena JSON formateada.\n",
    "- El diccionario contiene:\n",
    "  - `meta`: Los metadatos de la ley.\n",
    "  - `preview_articulos`: Solo los tres primeros artículos para una inspección rápida.\n",
    "- `ensure_ascii=False` preserva los caracteres especiales.\n",
    "- `indent=4` hace que el JSON sea legible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6cd018b-eada-4d7f-87ca-b94b1a9c07c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"meta\": {\n",
      "        \"numero_ley\": \"213\",\n",
      "        \"fecha_promulgacion\": \"29-06-1993\",\n",
      "        \"fecha_publicacion\": \"29-10-1993\"\n",
      "    },\n",
      "    \"preview_articulos\": [\n",
      "        {\n",
      "            \"articulo_numero\": 1,\n",
      "            \"libro\": \"libro primero\",\n",
      "            \"libro_numero\": 1,\n",
      "            \"titulo\": \"titulo primero\",\n",
      "            \"capitulo\": \"capitulo i\",\n",
      "            \"capitulo_numero\": 1,\n",
      "            \"capitulo_descripcion\": \"del objeto y aplicación del código\",\n",
      "            \"articulo\": \"este código tiene por objeto establecer normas para regular las relaciones entre los trabajadores y empleadores, concernientes a la prestación subordinada y retribuida de la actividad laboral.\"\n",
      "        },\n",
      "        {\n",
      "            \"articulo_numero\": 2,\n",
      "            \"libro\": \"libro primero\",\n",
      "            \"libro_numero\": 1,\n",
      "            \"titulo\": \"titulo primero\",\n",
      "            \"capitulo\": \"capitulo i\",\n",
      "            \"capitulo_numero\": 1,\n",
      "            \"capitulo_descripcion\": \"del objeto y aplicación del código\",\n",
      "            \"articulo\": \"estarán sujetos a las disposiciones del presente código:los trabajadores intelectuales, manuales o técnicos en relación de dependencia y sus empleadores. los profesores de institutos de enseñanza privada y quienes ejerzan la práctica deportiva profesional.los sindicatos de trabajadores y empleadores del sector privado.los trabajadores de las empresas del estado y de las empresas municipales.los demás trabajadores del estado, sean de la administración central o de entes descentralizados los de las municipalidades y departamentos, serán regidos por ley especial.están excluidos los miembros de las fuerzas armadas y de la policía.\"\n",
      "        },\n",
      "        {\n",
      "            \"articulo_numero\": 3,\n",
      "            \"libro\": \"libro primero\",\n",
      "            \"libro_numero\": 1,\n",
      "            \"titulo\": \"titulo primero\",\n",
      "            \"capitulo\": \"capitulo i\",\n",
      "            \"capitulo_numero\": 1,\n",
      "            \"capitulo_descripcion\": \"del objeto y aplicación del código\",\n",
      "            \"articulo\": \"los derechos reconocidos por este código a los trabajadores no podrán ser objeto de renuncia, transacción o limitación convencional. será nulo todo pacto contrario.las leyes que los establecen obligan y benefician a todos los trabajadores y empleadores de la república, sean nacionales o extranjeros y se inspirarán en los principios contenidos en la declaración universal de los derechos humanos, aprobada y proclamada por la asamblea general de las naciones unidas el 10 de diciembre de 1948, la declaración americana de los derechos y deberes del hombre, proclamada por la novena conferencia panamericana de bogotá el día 2 de mayo de 1948 y en los demás convenios internacionales del trabajo ratificados y canjeados por el paraguay que integran el derecho positivo.\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8148200-e1db-4cb6-bdbf-d62cc148c61d",
   "metadata": {},
   "source": [
    "# Save Parsed Data to JSON / Guardar Datos Parseados en JSON\n",
    "\n",
    "This function saves the parsed law data into a JSON file:\n",
    "\n",
    "- `save_parsed_json(parsed, filename, out_dir)`:\n",
    "  - `parsed`: The dictionary containing `meta` and `articulos`.\n",
    "  - `filename`: Name of the JSON file to create (default `\"codigo_trabajo_articulos.json\"`).\n",
    "  - `out_dir`: Directory to save the file (default `\"../data/processed\"`).\n",
    "- Ensures the output directory exists with `mkdir(parents=True, exist_ok=True)`.\n",
    "- Writes the JSON data with `ensure_ascii=False` to preserve special characters and `indent=2` for readability.\n",
    "- Prints the path of the saved file and the total number of articles.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función guarda los datos parseados de la ley en un archivo JSON:\n",
    "\n",
    "- `save_parsed_json(parsed, filename, out_dir)`:\n",
    "  - `parsed`: Diccionario que contiene `meta` y `articulos`.\n",
    "  - `filename`: Nombre del archivo JSON a crear (por defecto `\"codigo_trabajo_articulos.json\"`).\n",
    "  - `out_dir`: Carpeta donde se guardará el archivo (por defecto `\"../data/processed\"`).\n",
    "- Asegura que la carpeta de salida exista usando `mkdir(parents=True, exist_ok=True)`.\n",
    "- Escribe los datos en JSON con `ensure_ascii=False` para preservar caracteres especiales y `indent=2` para legibilidad.\n",
    "- Imprime la ruta del archivo guardado y el número total de artículos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55758ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_parsed_json(parsed, filename=\"codigo_trabajo_articulos.json\", out_dir=\"../data/processed\"):\n",
    "    out_dir = Path(out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / filename\n",
    "\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(parsed, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58a1cf55-eb69-4f17-8610-c4db573262e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ../data/processed/codigo_trabajo_articulos.json\n",
      "Artículos totales: 410\n"
     ]
    }
   ],
   "source": [
    "save_parsed_json(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f220b86",
   "metadata": {},
   "source": [
    "# System Analysis and Improvements / Análisis y Mejoras del Sistema\n",
    "\n",
    "*This section documents the development process, debugging, and improvements implemented during the creation of the legal data processing system.*\n",
    "\n",
    "---\n",
    "\n",
    "*Esta sección documenta el proceso de desarrollo, debugging y mejoras implementadas durante la creación del sistema de procesamiento de datos legales.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18f66d2",
   "metadata": {},
   "source": [
    "# Solución de Regex para Capturar Todos los Artículos / Regex Solution to Capture All Articles\n",
    "\n",
    "During the system development, we identified a critical issue: **some articles were not being captured** due to variations in the official site’s HTML format.\n",
    "\n",
    "**Identified Problem**\n",
    "\n",
    "The original regex pattern was too strict:\n",
    "```python\n",
    "# Original (problematic) pattern\n",
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-\\s*$\", re.IGNORECASE)\n",
    "````\n",
    "\n",
    "**Issues:**\n",
    "\n",
    "* Required the line to **end** with a dash (`-`)\n",
    "* Did not handle variations in the HTML format\n",
    "* Articles 95, 232, and 374 were not captured\n",
    "\n",
    "**HTML Analysis**\n",
    "\n",
    "The HTML had inconsistent formats:\n",
    "\n",
    "* **Standard format**: `Artículo XXX°.-`\n",
    "* **Problematic format**: `<strong>Artículo XXX°.</strong>-`\n",
    "\n",
    "**Implemented Solution**\n",
    "\n",
    "```python\n",
    "# Corrected pattern (flexible but precise)\n",
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-?\\s*\", re.IGNORECASE)\n",
    "```\n",
    "\n",
    "**Key changes:**\n",
    "\n",
    "1. **Optional dash** (`-?`) to handle variations\n",
    "2. **Keep `^`** to avoid false matches in the middle of lines\n",
    "3. **Use `match()`** instead of `search()` for precision\n",
    "\n",
    "**Result**\n",
    "\n",
    "* **413 unique articles** correctly captured\n",
    "* **No duplicates** after the fix\n",
    "* **Problematic articles** (95, 232, 374) included\n",
    "* **Automatic data integrity validation** in place\n",
    "\n",
    "---\n",
    "\n",
    "Durante el desarrollo del sistema, identificamos un problema crítico: **algunos artículos no se capturaban** debido a variaciones en el formato HTML del sitio oficial.\n",
    "\n",
    "**Problema Identificado**\n",
    "\n",
    "El patrón regex original era demasiado estricto:\n",
    "```python\n",
    "# Patrón original (problemático)\n",
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-\\s*$\", re.IGNORECASE)\n",
    "```\n",
    "\n",
    "**Problemas:**\n",
    "- Requería que la línea **terminara** con un guión (`-`)\n",
    "- No manejaba variaciones en el formato HTML\n",
    "- Artículos 95, 232 y 374 no se capturaban\n",
    "\n",
    "**Análisis del HTML**\n",
    "\n",
    "El HTML tenía formatos inconsistentes:\n",
    "- **Formato estándar**: `Artículo XXX°.-`\n",
    "- **Formato problemático**: `<strong>Artículo XXX°.</strong>-`\n",
    "\n",
    "**Solución Implementada**\n",
    "\n",
    "```python\n",
    "# Patrón corregido (flexible pero preciso)\n",
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-?\\s*\", re.IGNORECASE)\n",
    "```\n",
    "\n",
    "**Cambios clave:**\n",
    "1. **Guión opcional** (`-?`) para manejar variaciones\n",
    "2. **Mantener `^`** para evitar capturas falsas en medio de líneas\n",
    "3. **Usar `match()`** en lugar de `search()` para precisión\n",
    "\n",
    "**Resultado**\n",
    "\n",
    "- **413 artículos únicos** capturados correctamente\n",
    "- **Sin duplicados** después de la corrección\n",
    "- **Artículos problemáticos** (95, 232, 374) incluidos\n",
    "- **Validación automática** de integridad de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b96f85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la solución corregida\n",
    "def debug_article_capture():\n",
    "    \"\"\"Script de debugging para identificar artículos problemáticos.\"\"\"\n",
    "    import json\n",
    "    from collections import Counter\n",
    "\n",
    "    # Cargar datos procesados\n",
    "    with open(\"../data/processed/codigo_trabajo_articulos.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Verificar duplicados y artículos faltantes\n",
    "    article_numbers = [art[\"articulo_numero\"] for art in data[\"articulos\"]]\n",
    "    counter = Counter(article_numbers)\n",
    "\n",
    "    duplicates = {num: count for num, count in counter.items() if count > 1}\n",
    "    missing = [i for i in range(1, 414) if i not in article_numbers]\n",
    "\n",
    "    # Verificar artículos problemáticos específicos\n",
    "    problematic_articles = [95, 232, 374]\n",
    "    for art_num in problematic_articles:\n",
    "        found = art_num in article_numbers\n",
    "\n",
    "    return {\n",
    "        \"total_articles\": len(data[\"articulos\"]),\n",
    "        \"unique_articles\": len(set(article_numbers)),\n",
    "        \"duplicates\": len(duplicates),\n",
    "        \"missing\": missing,\n",
    "        \"problematic_found\": all(art in article_numbers for art in problematic_articles),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14cc757b-0f9d-45fd-8d0b-b7fa7768a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Análisis de Captura de Artículos:\n",
      "   Artículos duplicados: 0\n",
      "   Artículos faltantes: [95, 232, 374]\n",
      "   Total procesados: 410\n",
      "   Artículos únicos: 410\n",
      "   Rango: 1 - 413\n",
      "\n",
      "🔍 Verificación de Artículos Problemáticos:\n",
      "   Artículo 95: ❌ Faltante\n",
      "   Artículo 232: ❌ Faltante\n",
      "   Artículo 374: ❌ Faltante\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar análisis sin cambios\n",
    "results = debug_article_capture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8c59f1e-af74-40d3-b6d6-784ce6ce3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICULO_PATTERN = re.compile(r\"^Art[íi]?t?culo\\s+(\\d+)\\s*(?:[°º])?\\s*\\.?\\s*-?\\s*\", re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "820ada75-7618-4119-a521-2e351b7ffb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = parse_law_text(texto_limpio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c839cc-c679-4b50-bd00-0b5ed08c34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ../data/processed/codigo_trabajo_articulos.json\n",
      "Artículos totales: 413\n"
     ]
    }
   ],
   "source": [
    "save_parsed_json(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7a31b7b-05b5-4a73-ad2d-6e67d82a9011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Análisis de Captura de Artículos:\n",
      "   Artículos duplicados: 0\n",
      "   Artículos faltantes: []\n",
      "   Total procesados: 413\n",
      "   Artículos únicos: 413\n",
      "   Rango: 1 - 413\n",
      "\n",
      "🔍 Verificación de Artículos Problemáticos:\n",
      "   Artículo 95: ✅ Capturado\n",
      "   Artículo 232: ✅ Capturado\n",
      "   Artículo 374: ✅ Capturado\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar análisis con cambios\n",
    "results = debug_article_capture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941eaa06",
   "metadata": {},
   "source": [
    "# Lessons Learned / Lecciones Aprendidas\n",
    "\n",
    "**Best Practices for Regex in Data Processing**\n",
    "\n",
    "**1. Flexibility vs. Precision**\n",
    "- **Problem**: Overly strict patterns fail with format variations  \n",
    "- **Solution**: Use flexible patterns but keep anchors (`^`, `$`) for accuracy  \n",
    "- **Example**: `-?` (optional dash) instead of `-` (mandatory dash)  \n",
    "\n",
    "**2. Systematic Debugging**\n",
    "- **Problem**: Subtle parsing errors can go unnoticed  \n",
    "- **Solution**: Create specific validation scripts to check integrity  \n",
    "- **Tools**: `Counter`, range verification, duplicate analysis  \n",
    "\n",
    "**3. Data Validation**\n",
    "- **Problem**: Assuming processing was successful without verification  \n",
    "- **Solution**: Validate both quantity and quality of extracted data  \n",
    "- **Metrics**: Unique element count, range verification, duplicate detection  \n",
    "\n",
    "**4. Rapid Iteration**\n",
    "- **Problem**: Large changes make root cause harder to identify  \n",
    "- **Solution**: Incremental approach with small changes and continuous validation  \n",
    "- **Process**: Identify → Analyze → Fix → Validate → Iterate  \n",
    "\n",
    "**Success Metrics**\n",
    "- **413 unique articles** captured  \n",
    "- **0 duplicates** after the fix  \n",
    "- **100% coverage** of problematic articles  \n",
    "- **Automatic validation** implemented  \n",
    "\n",
    "---\n",
    "\n",
    "**Mejores Prácticas para Regex en Procesamiento de Datos**\n",
    "\n",
    "**1. Flexibilidad vs Precisión**\n",
    "- **Problema**: Patrones demasiado estrictos fallan con variaciones de formato\n",
    "- **Solución**: Usar patrones flexibles pero mantener anclas (`^`, `$`) para precisión\n",
    "- **Ejemplo**: `-?` (guión opcional) en lugar de `-` (guión obligatorio)\n",
    "\n",
    "**2. Debugging Sistemático**\n",
    "- **Problema**: Errores sutiles en parsing pueden pasar desapercibidos\n",
    "- **Solución**: Crear scripts de validación específicos para verificar integridad\n",
    "- **Herramientas**: `Counter`, verificación de rangos, análisis de duplicados\n",
    "\n",
    "**3. Validación de Datos**\n",
    "- **Problema**: Asumir que el procesamiento fue exitoso sin verificar\n",
    "- **Solución**: Validar tanto cantidad como calidad de datos extraídos\n",
    "- **Métricas**: Conteo de elementos únicos, verificación de rangos, detección de duplicados\n",
    "\n",
    "**4. Iteración Rápida**\n",
    "- **Problema**: Cambios grandes dificultan identificar la causa raíz\n",
    "- **Solución**: Enfoque incremental con cambios pequeños y validación continua\n",
    "- **Proceso**: Identificar → Analizar → Corregir → Validar → Iterar\n",
    "\n",
    "**Métricas de Éxito**\n",
    "\n",
    "- **413 artículos únicos** capturados\n",
    "- **0 duplicados** después de la corrección\n",
    "- **100% de cobertura** de artículos problemáticos\n",
    "- **Validación automática** implementada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a520c7",
   "metadata": {},
   "source": [
    "# Proposed Improvements: Validation and Quality Control / Mejoras Propuestas: Validación y Control de Calidad\n",
    "\n",
    "Once we have extracted and structured the articles, it is crucial to **validate the quality and integrity** of the processed data. This step is fundamental to ensure that our RAG system has reliable information. Although the current system works correctly, these additional validations would significantly improve the robustness of the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "Una vez que hemos extraído y estructurado los artículos, es crucial **validar la calidad y integridad** de los datos procesados. Este paso es fundamental para garantizar que nuestro sistema RAG tenga información confiable. Aunque el sistema actual funciona correctamente, estas validaciones adicionales mejorarían significativamente la robustez del pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f65d8",
   "metadata": {},
   "source": [
    "**Automatic Structure Validation / Validación Automática de Estructura**\n",
    "\n",
    "This function validates the integrity and quality of the processed data by checking required fields, valid numbers, and non-empty content.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función valida la integridad y calidad de los datos procesados, verificando campos requeridos, números válidos y contenido no vacío.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4175a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_processed_data(articles):\n",
    "    \"\"\"Valida la integridad y calidad de los datos procesados.\"\"\"\n",
    "    validation_results = {\n",
    "        \"total_articles\": len(articles),\n",
    "        \"valid_articles\": 0,\n",
    "        \"invalid_articles\": [],\n",
    "        \"missing_fields\": [],\n",
    "        \"quality_score\": 0.0,\n",
    "    }\n",
    "\n",
    "    required_fields = [\"articulo_numero\", \"libro\", \"capitulo\", \"articulo\"]\n",
    "\n",
    "    for article in articles:\n",
    "        article_valid = True\n",
    "        article_issues = []\n",
    "\n",
    "        # Verificar campos requeridos\n",
    "        for field in required_fields:\n",
    "            if field not in article or not article[field]:\n",
    "                article_issues.append(f\"Campo faltante: {field}\")\n",
    "                article_valid = False\n",
    "\n",
    "        # Verificar que el número de artículo sea válido\n",
    "        if \"articulo_numero\" in article:\n",
    "            art_num = article[\"articulo_numero\"]\n",
    "            if not isinstance(art_num, int) or art_num < 1 or art_num > 413:\n",
    "                article_issues.append(f\"Número de artículo inválido: {art_num}\")\n",
    "                article_valid = False\n",
    "\n",
    "        # Verificar que el contenido no esté vacío\n",
    "        if \"articulo\" in article and len(article[\"articulo\"].strip()) < 10:\n",
    "            article_issues.append(\"Contenido del artículo demasiado corto\")\n",
    "            article_valid = False\n",
    "\n",
    "        if article_valid:\n",
    "            validation_results[\"valid_articles\"] += 1\n",
    "        else:\n",
    "            validation_results[\"invalid_articles\"].append(\n",
    "                {\n",
    "                    \"articulo_numero\": article.get(\"articulo_numero\", \"desconocido\"),\n",
    "                    \"issues\": article_issues,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # Calcular score de calidad\n",
    "    validation_results[\"quality_score\"] = (\n",
    "        validation_results[\"valid_articles\"] / validation_results[\"total_articles\"]\n",
    "    )\n",
    "\n",
    "    return validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3003bcc3-4bfb-47d1-8ddc-08a043483007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación completada: 413/413 artículos válidos\n",
      "Score de calidad: 100.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_articles': 413,\n",
       " 'valid_articles': 413,\n",
       " 'invalid_articles': [],\n",
       " 'missing_fields': [],\n",
       " 'quality_score': 1.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_processed_data(parsed.get(\"articulos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd4d7d",
   "metadata": {},
   "source": [
    "**Data Completeness Verification / Verificación de Completitud de Datos**\n",
    "\n",
    "This function checks that all expected articles are present and detects duplicates.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función verifica que todos los artículos esperados estén presentes y detecta duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29ca09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_completeness(articles):\n",
    "    \"\"\"Verifica que todos los artículos esperados estén presentes.\"\"\"\n",
    "\n",
    "    article_numbers = [art[\"articulo_numero\"] for art in articles if \"articulo_numero\" in art]\n",
    "\n",
    "    # Verificar rango completo (1-413)\n",
    "    expected_range = set(range(1, 414))\n",
    "    found_numbers = set(article_numbers)\n",
    "\n",
    "    missing_articles = expected_range - found_numbers\n",
    "    duplicate_articles = [num for num in article_numbers if article_numbers.count(num) > 1]\n",
    "\n",
    "    completeness_report = {\n",
    "        \"expected_total\": 413,\n",
    "        \"found_total\": len(found_numbers),\n",
    "        \"missing_articles\": sorted(list(missing_articles)),\n",
    "        \"duplicate_articles\": duplicate_articles,\n",
    "        \"completeness_percentage\": len(found_numbers) / 413 * 100,\n",
    "    }\n",
    "\n",
    "    if missing_articles:\n",
    "        pass\n",
    "\n",
    "    if duplicate_articles:\n",
    "        pass\n",
    "\n",
    "    return completeness_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b370f5a9-66d1-4d7b-ae60-c54230d4ba35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completitud de datos: 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'expected_total': 413,\n",
       " 'found_total': 413,\n",
       " 'missing_articles': [],\n",
       " 'duplicate_articles': [],\n",
       " 'completeness_percentage': 100.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_data_completeness(parsed.get(\"articulos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5bbd9",
   "metadata": {},
   "source": [
    "** Content Quality Analysis / Análisis de Calidad de Contenido**\n",
    "\n",
    "This function analyzes the quality of the extracted content, providing metrics on length, special characters, and numbers.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función analiza la calidad del contenido extraído, proporcionando métricas sobre longitud, caracteres especiales y números.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c569195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_content_quality(articles):\n",
    "    \"\"\"Analiza la calidad del contenido extraído.\"\"\"\n",
    "    quality_metrics = {\n",
    "        \"avg_content_length\": 0,\n",
    "        \"short_articles\": 0,  # < 50 caracteres\n",
    "        \"medium_articles\": 0,  # 50-200 caracteres\n",
    "        \"long_articles\": 0,  # > 200 caracteres\n",
    "        \"articles_with_special_chars\": 0,\n",
    "        \"articles_with_numbers\": 0,\n",
    "    }\n",
    "\n",
    "    content_lengths = []\n",
    "\n",
    "    for article in articles:\n",
    "        if \"articulo\" not in article:\n",
    "            continue\n",
    "\n",
    "        content = article[\"articulo\"]\n",
    "        content_length = len(content.strip())\n",
    "        content_lengths.append(content_length)\n",
    "\n",
    "        # Clasificar por longitud\n",
    "        if content_length < 50:\n",
    "            quality_metrics[\"short_articles\"] += 1\n",
    "        elif content_length <= 200:\n",
    "            quality_metrics[\"medium_articles\"] += 1\n",
    "        else:\n",
    "            quality_metrics[\"long_articles\"] += 1\n",
    "\n",
    "        # Verificar características especiales\n",
    "        if any(char in content for char in [\"°\", \"º\", \"§\", \"¶\"]):\n",
    "            quality_metrics[\"articles_with_special_chars\"] += 1\n",
    "\n",
    "        if any(char.isdigit() for char in content):\n",
    "            quality_metrics[\"articles_with_numbers\"] += 1\n",
    "\n",
    "    if content_lengths:\n",
    "        quality_metrics[\"avg_content_length\"] = sum(content_lengths) / len(content_lengths)\n",
    "\n",
    "    return quality_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac34b6c0-47d3-4ed8-9838-ea4e662fe153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis de calidad completado\n",
      "Longitud promedio de artículos: 438.2 caracteres\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'avg_content_length': 438.17433414043586,\n",
       " 'short_articles': 0,\n",
       " 'medium_articles': 98,\n",
       " 'long_articles': 315,\n",
       " 'articles_with_special_chars': 3,\n",
       " 'articles_with_numbers': 64}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_content_quality(parsed.get(\"articulos\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c0a07",
   "metadata": {},
   "source": [
    "**Quality Report Generation / Generación de Reporte de Calidad**\n",
    "\n",
    "This function generates a comprehensive data quality report by combining all the previous validations.\n",
    "\n",
    "---\n",
    "\n",
    "Esta función genera un reporte completo de calidad de datos combinando todas las validaciones anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efebd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quality_report(articles):\n",
    "    \"\"\"Genera un reporte completo de calidad de datos.\"\"\"\n",
    "    validation_results = validate_processed_data(articles)\n",
    "    completeness_report = verify_data_completeness(articles)\n",
    "    quality_metrics = analyze_content_quality(articles)\n",
    "\n",
    "    report = f\"\"\"\n",
    "📊 REPORTE DE CALIDAD DE DATOS PROCESADOS\n",
    "{\"=\" * 50}\n",
    "\n",
    "✅ VALIDACIÓN DE ESTRUCTURA:\n",
    "   • Artículos válidos: {validation_results[\"valid_articles\"]}/{validation_results[\"total_articles\"]}\n",
    "   • Score de calidad: {validation_results[\"quality_score\"]:.2%}\n",
    "   • Artículos con problemas: {len(validation_results[\"invalid_articles\"])}\n",
    "\n",
    "📋 COMPLETITUD DE DATOS:\n",
    "   • Artículos encontrados: {completeness_report[\"found_total\"]}/413\n",
    "   • Completitud: {completeness_report[\"completeness_percentage\"]:.1f}%\n",
    "   • Artículos faltantes: {len(completeness_report[\"missing_articles\"])}\n",
    "   • Artículos duplicados: {len(completeness_report[\"duplicate_articles\"])}\n",
    "\n",
    "📝 ANÁLISIS DE CONTENIDO:\n",
    "   • Longitud promedio: {quality_metrics[\"avg_content_length\"]:.1f} caracteres\n",
    "   • Artículos cortos (< 50 chars): {quality_metrics[\"short_articles\"]}\n",
    "   • Artículos medianos (50-200 chars): {quality_metrics[\"medium_articles\"]}\n",
    "   • Artículos largos (> 200 chars): {quality_metrics[\"long_articles\"]}\n",
    "   • Con caracteres especiales: {quality_metrics[\"articles_with_special_chars\"]}\n",
    "   • Con números: {quality_metrics[\"articles_with_numbers\"]}\n",
    "\n",
    "🎯 ESTADO GENERAL: {\"✅ EXCELENTE\" if validation_results[\"quality_score\"] > 0.95 else \"⚠️ REQUIERE ATENCIÓN\"}\n",
    "\"\"\"\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2644f45",
   "metadata": {},
   "source": [
    "**Improvements Demonstration / Demostración de las Mejoras**\n",
    "\n",
    "Now we are going to test the validation and quality control functions with the processed data:\n",
    "\n",
    "---\n",
    "\n",
    "Ahora vamos a probar las funciones de validación y control de calidad con los datos procesados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11738283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validación completada: 413/413 artículos válidos\n",
      "Score de calidad: 100.00%\n",
      "Completitud de datos: 100.0%\n",
      "Análisis de calidad completado\n",
      "Longitud promedio de artículos: 438.2 caracteres\n",
      "\n",
      "📊 REPORTE DE CALIDAD DE DATOS PROCESADOS\n",
      "==================================================\n",
      "\n",
      "✅ VALIDACIÓN DE ESTRUCTURA:\n",
      "   • Artículos válidos: 413/413\n",
      "   • Score de calidad: 100.00%\n",
      "   • Artículos con problemas: 0\n",
      "\n",
      "📋 COMPLETITUD DE DATOS:\n",
      "   • Artículos encontrados: 413/413\n",
      "   • Completitud: 100.0%\n",
      "   • Artículos faltantes: 0\n",
      "   • Artículos duplicados: 0\n",
      "\n",
      "📝 ANÁLISIS DE CONTENIDO:\n",
      "   • Longitud promedio: 438.2 caracteres\n",
      "   • Artículos cortos (< 50 chars): 0\n",
      "   • Artículos medianos (50-200 chars): 98\n",
      "   • Artículos largos (> 200 chars): 315\n",
      "   • Con caracteres especiales: 3\n",
      "   • Con números: 64\n",
      "\n",
      "🎯 ESTADO GENERAL: ✅ EXCELENTE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generar reporte completo de calidad\n",
    "quality_report = generate_quality_report(parsed[\"articulos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee86d04",
   "metadata": {},
   "source": [
    "**Benefits of Implementing These Improvements / Beneficios de Implementar Estas Mejoras**\n",
    "\n",
    "- **Early Problem Detection**: Identify errors before they reach the RAG system  \n",
    "- **Quality Metrics**: Quantify the quality of the processed data  \n",
    "- **Improved Debugging**: Detailed reports to facilitate issue resolution  \n",
    "- **System Robustness**: Automatic validations that prevent production failures  \n",
    "- **Continuous Monitoring**: Ability to detect quality degradation over time  \n",
    "\n",
    "*These functions can be easily integrated into the current system by adding them to the `extract_law_text.py` file and calling them after the article processing step.*\n",
    "\n",
    "---\n",
    "\n",
    "- **Detección Temprana de Problemas**: Identificar errores antes de que lleguen al sistema RAG\n",
    "- **Métricas de Calidad**: Cuantificar la calidad de los datos procesados\n",
    "- **Debugging Mejorado**: Reportes detallados para facilitar la resolución de problemas\n",
    "- **Robustez del Sistema**: Validaciones automáticas que previenen fallos en producción\n",
    "- **Monitoreo Continuo**: Capacidad de detectar degradación de calidad a lo largo del tiempo\n",
    "\n",
    "*Estas funciones se pueden integrar fácilmente al sistema actual agregándolas al archivo `extract_law_text.py` y llamándolas después del procesamiento de artículos.*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
