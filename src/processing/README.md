<div align="center">

**Language / Idioma:**
[üá∫üá∏ English](#legal-text-processing) | [üá™üá∏ Espa√±ol](#procesamiento-de-texto-legal)

</div>

---

# **Legal Text Processing**

This directory contains scripts for extracting and processing text from Paraguay's Labor Code.


| Script | Description | Status |
|--------|-------------|--------|
| `extract_law_text.py` | Main script for extracting and processing text from Paraguay's Labor Code from its official source | ‚úÖ Active |

## **`extract_law_text.py`**

Main script for extracting and processing text from Paraguay's Labor Code from its official source.

### **Features**

- **Two execution modes**:
  - **Local**: Saves files to local filesystem
  - **GCS**: Creates temporary folders and uploads JSON to Google Cloud Storage

- **Functionalities**:
  - Automatic HTML download from official site
  - Text extraction and cleaning
  - Structured article segmentation
  - Quality validation and reporting
  - JSON format saving
  - Phoenix/OpenTelemetry tracing for observability (always enabled)

### **Installation**

- See the [UV documentation](https://github.com/astral-sh/uv) for more details.

```bash
# Install dependencies using uv
uv sync
```

### **Quick Start**

#### **Local Mode (default)**

```bash
# Basic execution
uv run extract_law_text.py

# Custom filenames
uv run extract_law_text.py --raw-filename mylaw.html --processed-filename myoutput.json

# Skip quality validation for faster processing
uv run extract_law_text.py --skip-quality-validation

# Local mode with custom output root (e.g., for Docker volume)
uv run extract_law_text.py --output-root /app

# Local mode with custom filenames
uv run extract_law_text.py --raw-filename ley.html --processed-filename salida.json
```

- The raw HTML will be saved to `data/raw/{raw-filename}` (default: `codigo_trabajo_py.html`) in the project root (not the current directory).
- The processed JSON will be saved to `data/processed/{processed-filename}` (default: `codigo_trabajo_articulos.json`) in the project root.

#### **Google Cloud Storage Mode**

```bash
# Basic GCS execution
uv run extract_law_text.py --mode gcs --bucket-name my-bucket

# Use local credentials (for local development)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --use-local-credentials

# GCS mode (Cloud Run or default credentials)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket

# GCS mode with local credentials (for local development)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --use-local-credentials

# GCS mode with custom filenames
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --raw-filename ley.html --processed-filename salida.json
```

- The raw HTML will always be uploaded to `raw/{raw-filename}` in the bucket (default: `codigo_trabajo_py.html`).
- The processed JSON will always be uploaded to `processed/{processed-filename}` in the bucket (default: `codigo_trabajo_articulos.json`).

### **Configuration**

#### **Command Line Arguments**

| Argument             | Description                                         | Required           | Default                        |
|---------------------|-----------------------------------------------------|--------------------|--------------------------------|
| `--mode`             | Execution mode: `local` or `gcs`                    | No                 | `local`                         |
| `--url`              | Law page URL                                        | No                 | Official URL                    |
| `--bucket-name`      | GCS bucket name (gcs mode)                          | Yes (for gcs mode) | -                               |
| `--raw-filename`     | Name for raw HTML file                              | No                 | `codigo_trabajo_py.html`        |
| `--processed-filename`| Name for processed JSON file                        | No                 | `codigo_trabajo_articulos.json` |
| `--use-local-credentials`| Force use of local credentials file (for local dev, not Cloud Run) | No                 | False                           |
| `--gcp-credentials-dir` | Path to the folder where the GCP .json credentials file is located (optional, useful for Docker) | No | Project root `.gcpcredentials` |
| `--output-root`        | Root directory for local output (data/raw and data/processed) (optional, useful for Docker) | No | Project root |
| `--phoenix-endpoint`   | Phoenix endpoint URL for tracing                    | No                 | `http://localhost:6006/v1/traces` |
| `--phoenix-project-name`| Phoenix project name for tracing                   | No                 | `lus-laboris-processing` |
| `--phoenix-log-level`  | Phoenix logging level (DEBUG/INFO/WARNING/ERROR)   | No                 | `INFO` |
| `--skip-quality-validation` | Skip quality validation and reporting | No | False |

#### **Google Cloud Storage Configuration**

To use GCS mode, you need to configure authentication:

- By default (recommended for Cloud Run), the script will use the environment's credentials (e.g., Cloud Run's default Service Account).
- If you use the `--use-local-credentials` flag, the script will look for a service account `.json` file in a `.gcpcredentials` folder at the project root and set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable automatically. This is useful for local development.
- You can override the credentials folder location with the `--gcp-credentials-dir` flag (recommended for Docker).

### **Quality Validation**

The script automatically validates processed data quality by:
- **Structure validation**: Checks required fields and valid article numbers (1-413)
- **Completeness verification**: Ensures all 413 articles are present without duplicates
- **Content analysis**: Analyzes article length, special characters, and content quality
- **Comprehensive reporting**: Generates detailed quality reports with metrics and status

Use `--skip-quality-validation` to disable validation for faster processing.

### **Output Structure**

The script generates a JSON file with the following structure:

```json
{
  "meta": {
    "numero_ley": "213",
    "fecha_promulgacion": "DD-MM-YYYY",
    "fecha_publicacion": "DD-MM-YYYY"
  },
  "articulos": [
    {
      "articulo_numero": 1,
      "libro": "libro primero",
      "libro_numero": 1,
      "titulo": "t√≠tulo i",
      "capitulo": "cap√≠tulo i",
      "capitulo_numero": 1,
      "capitulo_descripcion": "chapter description",
      "articulo": "article content..."
    }
  ]
}
```

### **Docker**

You can build and run the script in a Docker container for maximum portability.

#### **Build the Image**

```bash
docker build -t labor-law-extractor .
```

#### **Local Mode**

You can run the script in local mode and persist output to a mounted volume:

```bash
# Get the absolute path to the data folder
DATA_DIR=$(realpath ../../data)

# Make sure to start Phoenix beforehand to avoid timeout warnings (the process will still run successfully)
docker run --rm \
  --network=monitoring_default \
  -v "${DATA_DIR}:/app/data" \
  labor-law-extractor \
  --output-root /app \
  --phoenix-endpoint http://phoenix:6006/v1/traces
```

This will save all output in your local 'data' folder.

#### **GCS Mode (mounting credentials)**

```bash
# Get the absolute path to the GCP credentials folder
GCP_CREDS=$(realpath ../../.gcpcredentials)

docker run --rm \
  -v "${GCP_CREDS}:/gcpcreds:ro" \
  labor-law-extractor \
  --mode gcs \
  --bucket-name py-labor-law-rag-bucket \
  --use-local-credentials \
  --gcp-credentials-dir /gcpcreds
```

This allows you to run the script in GCS mode from Docker, mounting the GCP credentials securely.

#### **Publishing to Docker Hub**

You can upload the generated Docker image to Docker Hub manually or automatically.

##### **Manual Method**

1. Load the environment variables from the `.env` file located at the project root (run this from the `src/processing` folder):
```bash
set -o allexport
source ../../.env
set +o allexport
```

2. Make sure you have a `.env` file at the project root with the variables:
   - `DOCKER_HUB_USERNAME`
   - `DOCKER_HUB_PASSWORD`
   - `DOCKER_IMAGE_NAME_PROCESSING`

3. Build the Docker image:
```bash
docker build -t "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" .
```

4. Log in to Docker Hub:
```bash
echo "$DOCKER_HUB_PASSWORD" | docker login --username "$DOCKER_HUB_USERNAME" --password-stdin
```

5. Tag the image with the date:
```bash
DATE_TAG=$(date +%Y%m%d)
docker tag "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

6. Push both tags:
```bash
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest"
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

> **Note:** The script and commands generate two tags: one with `latest` and one with the current date (`YYYYMMDD`).
> **Best practice:** In production, always use the date tag (`YYYYMMDD`) to avoid running unexpected versions that may be under the `latest` tag.

For more details about Docker usage (including Compose and Hub), see the guide:
- [docker_guide.md](../../docs/docker_guide.md)

##### **Automatic Method (recommended)**

You can use the `docker_build_push.sh` script to automate the entire process. The script looks for the `.env` file at the project root (two levels above the `processing` folder).

```bash
bash docker_build_push.sh
```

The script will validate the required variables, build the image, tag it, and push it to Docker Hub with both tags. For more information, see:
- [docker_guide.md](../../docs/docker_guide.md)

### **Phoenix Monitoring**

The script includes built-in support for Phoenix/OpenTelemetry tracing to monitor execution and performance. **Tracing is always enabled** when you run the script.

> **For detailed Phoenix setup and advanced features, see the [Phoenix Guide](../../docs/phoenix_guide.md)**

#### **Features**

- Automatic HTTP request instrumentation
- Custom spans for all major operations (download, parsing, saving)
- Captures metadata: file sizes, article counts, execution times, errors
- **Automatic verification**: Checks if Phoenix is reachable before processing
- **Graceful degradation**: If Phoenix is unavailable, shows a warning but continues processing (traces won't be collected)

#### **Configuration**

Phoenix tracing is configured via command-line arguments with sensible defaults:

```bash
# Use default Phoenix configuration (localhost)
uv run extract_law_text.py

# Custom Phoenix endpoint
uv run extract_law_text.py --phoenix-endpoint http://localhost:6006/v1/traces

# Custom Phoenix project name
uv run extract_law_text.py --phoenix-project-name my-project

# Both custom Phoenix settings
uv run extract_law_text.py --phoenix-endpoint https://your-instance.phoenix.arize.com/v1/traces --phoenix-project-name my-project
```

#### **Usage**

1. Start Phoenix (local):
   ```bash
   cd ../../services/monitoring
   docker-compose up -d
   ```

2. Run the script normally (tracing is automatic):
   ```bash
   uv run extract_law_text.py --mode local
   ```

3. View traces at: http://localhost:6006

#### **Logging System**

The script implements a separate logging system that distinguishes between main process messages and Phoenix/debug messages:

**Main Process Logs:**
```
10:30:15 [PROCESO] üîÑ Starting processing in mode: LOCAL
10:30:15 [PROCESO] üîÑ Downloading from: https://example.com/ley
10:30:16 [PROCESO] ‚úÖ Page downloaded and saved to: data/raw/ley.html
10:30:16 [PROCESO] ‚úÖ Law content extracted successfully
10:30:17 [PROCESO] ‚úÖ Saved locally: data/processed/articulos.json
10:30:17 [PROCESO] üìä Total articles: 150
10:30:17 [PROCESO] ‚úÖ Process completed successfully!
```

**Phoenix/Debug Logs:**
```
10:30:15 [PHOENIX] Phoenix tracing initialized correctly
10:30:15 [PHOENIX] Session created: 550e8400-e29b-41d4-a716-446655440000
10:30:15 [PHOENIX] Starting Phoenix span: download_law_page (kind: CLIENT) [Session: 550e8400]
10:30:16 [PHOENIX] Ending Phoenix span: download_law_page
10:30:17 [PHOENIX] Session ended: 550e8400-e29b-41d4-a716-446655440000
```

**Log Level Control:**

```bash
# See all Phoenix logs (full debug)
uv run extract_law_text.py --phoenix-log-level DEBUG

# Only important Phoenix information (default)
uv run extract_law_text.py --phoenix-log-level INFO

# Only Phoenix warnings and errors
uv run extract_law_text.py --phoenix-log-level WARNING

# Only critical Phoenix errors
uv run extract_law_text.py --phoenix-log-level ERROR
```

**Benefits:**
- **Clear separation**: Main process vs debugging/tracing
- **Granular control**: Adjust Phoenix verbosity level
- **Professional format**: Consistent timestamps and categorization
- **Easy filtering**: Quickly identify important messages

# **Important Notes**

- **Tracing is always active**: The script always attempts to send traces
- **Phoenix verification**: Before processing, the script checks if Phoenix is reachable
- **Warning if unavailable**: If Phoenix is not running, you'll see warnings but processing continues
- **No data loss**: If Phoenix becomes available during execution, traces will be sent
- GCS mode creates temporary directories that are automatically cleaned up when finished
- For GCS mode, ensure you have write permissions to the specified bucket
- The script handles network and processing errors robustly
- Temporary files are created with the `lus_laboris_` prefix for easy identification

---

# **Procesamiento de Texto Legal**

Este directorio contiene scripts para extraer y procesar texto del C√≥digo Laboral de Paraguay.


| Script | Descripci√≥n | Estado |
|--------|-------------|--------|
| `extract_law_text.py` | Script principal para extraer y procesar el texto del C√≥digo Laboral de Paraguay desde su fuente oficial | ‚úÖ Activo |

## **`extract_law_text.py`**

Script principal para extraer y procesar el texto del C√≥digo Laboral de Paraguay desde su fuente oficial.

### **Caracter√≠sticas**

- **Dos modos de ejecuci√≥n**:
  - **Local**: Guarda archivos en el sistema de archivos local
  - **GCS**: Crea carpetas temporales y sube el JSON a Google Cloud Storage

- **Funcionalidades**:
  - Descarga autom√°tica del HTML desde el sitio oficial
  - Extracci√≥n y limpieza del texto
  - Segmentaci√≥n en art√≠culos estructurados
  - Validaci√≥n de calidad y reportes
  - Guardado en formato JSON
  - Trazas Phoenix/OpenTelemetry para observabilidad (siempre activo)

### **Instalaci√≥n**

- Consulta la [documentaci√≥n de UV](https://github.com/astral-sh/uv) para m√°s detalles.

```bash
# Instalar dependencias usando uv
uv sync
```

### **Inicio R√°pido**

#### **Modo Local (por defecto)**

```bash
# Ejecuci√≥n b√°sica
uv run extract_law_text.py

# Personalizando nombres de archivos
uv run extract_law_text.py --raw-filename mi_ley.html --processed-filename salida.json

# Omitir validaci√≥n de calidad para procesamiento m√°s r√°pido
uv run extract_law_text.py --skip-quality-validation

# Modo local con ra√≠z de salida personalizada (por ejemplo, para volumen Docker)
uv run extract_law_text.py --output-root /app

# Modo local con nombres personalizados
uv run extract_law_text.py --raw-filename ley.html --processed-filename salida.json
```

- El HTML crudo se guardar√° en `data/raw/{raw-filename}` (por defecto: `codigo_trabajo_py.html`) en la ra√≠z del proyecto (no en el directorio actual).
- El JSON procesado se guardar√° en `data/processed/{processed-filename}` (por defecto: `codigo_trabajo_articulos.json`) en la ra√≠z del proyecto.

#### **Modo Google Cloud Storage**

```bash
# Ejecuci√≥n b√°sica con GCS
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket

# Forzar uso de credenciales locales (para desarrollo local)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --use-local-credentials

# Modo GCS (Cloud Run o credenciales por defecto)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket

# Modo GCS con credenciales locales (para desarrollo local)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --use-local-credentials

# Modo GCS con nombres personalizados
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --raw-filename ley.html --processed-filename salida.json
```

- El HTML crudo siempre se subir√° a `raw/{raw-filename}` en el bucket (por defecto: `codigo_trabajo_py.html`).
- El JSON procesado siempre se subir√° a `processed/{processed-filename}` en el bucket (por defecto: `codigo_trabajo_articulos.json`).

### **Configuraci√≥n**

#### **Argumentos de L√≠nea de Comandos**

| Argumento             | Descripci√≥n                                         | Requerido           | Por Defecto                    |
|-----------------------|-----------------------------------------------------|---------------------|-------------------------------|
| `--mode`              | Modo de ejecuci√≥n: `local` o `gcs`                  | No                  | `local`                       |
| `--url`               | URL de la p√°gina de la ley                          | No                  | URL oficial                   |
| `--bucket-name`       | Nombre del bucket de GCS (modo gcs)                 | S√≠ (para modo gcs)  | -                             |
| `--raw-filename`      | Nombre para el archivo HTML crudo                   | No                  | `codigo_trabajo_py.html`      |
| `--processed-filename`| Nombre para el archivo JSON procesado               | No                  | `codigo_trabajo_articulos.json`|
| `--use-local-credentials`| Forzar uso de credenciales locales (para desarrollo local, no Cloud Run) | No                  | False                         |
| `--gcp-credentials-dir` | Ruta a la carpeta donde buscar el archivo .json de credenciales de GCP (opcional, util para Docker) | No | `.gcpcredentials` en la ra√≠z |
| `--output-root`        | Ra√≠z donde se crear√°n las carpetas data/raw y data/processed en modo local (opcional, √∫til para Docker) | No | Ra√≠z del proyecto |
| `--phoenix-endpoint`   | URL del endpoint de Phoenix para enviar trazas      | No                  | `http://localhost:6006/v1/traces` |
| `--phoenix-project-name`| Nombre del proyecto para las trazas de Phoenix     | No                  | `lus-laboris-processing` |
| `--phoenix-log-level`  | Nivel de logging de Phoenix (DEBUG/INFO/WARNING/ERROR) | No               | `INFO` |
| `--skip-quality-validation` | Omitir validaci√≥n de calidad y reportes | No | False |

#### **Configuraci√≥n para Google Cloud Storage**

Para usar el modo GCS, necesitas configurar la autenticaci√≥n:

- Por defecto (recomendado para Cloud Run), el script usar√° las credenciales del entorno (por ejemplo, la Service Account por defecto de Cloud Run).
- Si usas el flag `--use-local-credentials`, el script buscar√° autom√°ticamente un archivo `.json` de cuenta de servicio en la carpeta `.gcpcredentials` en la ra√≠z del proyecto y establecer√° la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS`. Esto es √∫til para desarrollo local.
- Puedes sobrescribir la ubicaci√≥n de la carpeta de credenciales con el flag `--gcp-credentials-dir` (recomendado para Docker).

### **Validaci√≥n de Calidad**

El script valida autom√°ticamente la calidad de los datos procesados mediante:
- **Validaci√≥n de estructura**: Verifica campos requeridos y n√∫meros de art√≠culo v√°lidos (1-413)
- **Verificaci√≥n de completitud**: Asegura que los 413 art√≠culos est√©n presentes sin duplicados
- **An√°lisis de contenido**: Analiza longitud de art√≠culos, caracteres especiales y calidad del contenido
- **Reportes comprensivos**: Genera reportes detallados de calidad con m√©tricas y estado

Usa `--skip-quality-validation` para deshabilitar la validaci√≥n y procesar m√°s r√°pido.

### **Estructura de Salida**

El script genera un archivo JSON con la siguiente estructura:

```json
{
  "meta": {
    "numero_ley": "213",
    "fecha_promulgacion": "DD-MM-YYYY",
    "fecha_publicacion": "DD-MM-YYYY"
  },
  "articulos": [
    {
      "articulo_numero": 1,
      "libro": "libro primero",
      "libro_numero": 1,
      "titulo": "t√≠tulo i",
      "capitulo": "cap√≠tulo i",
      "capitulo_numero": 1,
      "capitulo_descripcion": "descripci√≥n del cap√≠tulo",
      "articulo": "contenido del art√≠culo..."
    }
  ]
}
```

### **Docker**

Puedes construir y ejecutar el script en un contenedor Docker para m√°xima portabilidad.

#### **Construir la Imagen**

```bash
docker build -t labor-law-extractor .
```

#### **Modo Local**

Puedes ejecutar el script en modo local y persistir la salida en un volumen montado:

```bash
# Obtener la ruta absoluta de la carpeta data
DATA_DIR=$(realpath ../../data)

# Asegurarse de levantar Phoenix previamente para evitar warnings de timeout (el proceso igual se ejecuta sin problemas)
docker run --rm \
  --network=monitoring_default \
  -v "${DATA_DIR}:/app/data" \
  labor-law-extractor \
  --output-root /app \
  --phoenix-endpoint http://phoenix:6006/v1/traces
```

Esto guardar√° toda la salida en tu carpeta local 'data'.

#### **Modo GCS (montando credenciales)**

```bash
# Obtener la ruta absoluta de la carpeta de credenciales GCP
GCP_CREDS=$(realpath ../../.gcpcredentials)

docker run --rm \
  -v "${GCP_CREDS}:/gcpcreds:ro" \
  labor-law-extractor \
  --mode gcs \
  --bucket-name py-labor-law-rag-bucket \
  --use-local-credentials \
  --gcp-credentials-dir /gcpcreds
```

Esto permite ejecutar el script en modo GCS desde Docker, montando las credenciales de GCP de forma segura.

#### **Publicar en Docker Hub**

Puedes subir la imagen Docker generada a Docker Hub de forma manual o autom√°tica.

##### **M√©todo Manual**

1. Carga las variables de entorno desde el archivo `.env` ubicado en la ra√≠z del proyecto (ejecuta esto desde la carpeta `src/processing`):
```bash
set -o allexport
source ../../.env
set +o allexport
```

2. Aseg√∫rate de tener un archivo `.env` en la ra√≠z del proyecto con las variables:
   - `DOCKER_HUB_USERNAME`
   - `DOCKER_HUB_PASSWORD`
   - `DOCKER_IMAGE_NAME_PROCESSING`

3. Construye la imagen Docker:
```bash
docker build -t "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" .
```

4. Inicia sesi√≥n en Docker Hub:
```bash
echo "$DOCKER_HUB_PASSWORD" | docker login --username "$DOCKER_HUB_USERNAME" --password-stdin
```

5. Etiqueta la imagen con la fecha:
```bash
DATE_TAG=$(date +%Y%m%d)
docker tag "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

6. Sube ambas etiquetas:
```bash
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest"
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

> **Nota:** El script y los comandos generan dos tags: uno con la palabra `latest` y otro con la fecha actual (formato `YYYYMMDD`).
> **Buena pr√°ctica:** En producci√≥n, siempre utiliza el tag de fecha (`YYYYMMDD`) para evitar ejecutar versiones inesperadas que puedan estar bajo el tag `latest`.

Para m√°s detalles sobre el uso de Docker (incluyendo Compose y Hub), consulta la gu√≠a:
- [docker_guide.md](../../docs/docker_guide.md)

##### **M√©todo Autom√°tico (recomendado)**

Puedes usar el script `docker_build_push.sh` que automatiza todo el proceso. El script busca el archivo `.env` en la ra√≠z del proyecto (dos niveles arriba de la carpeta `processing`).

```bash
bash docker_build_push.sh
```

El script validar√° las variables necesarias, construir√° la imagen, la etiquetar√° y la subir√° a Docker Hub con los tags correspondientes. Para m√°s informaci√≥n, revisa:
- [docker_guide.md](../../docs/docker_guide.md)

### **Monitoreo Phoenix**

El script incluye soporte integrado para trazas Phoenix/OpenTelemetry para monitorear la ejecuci√≥n y rendimiento. **El trazado siempre est√° activo** cuando ejecutas el script.

> **Para configuraci√≥n detallada de Phoenix y caracter√≠sticas avanzadas, consulta la [Gu√≠a de Phoenix](../../docs/phoenix_guide.md)**

##### **Caracter√≠sticas**

- Instrumentaci√≥n autom√°tica de peticiones HTTP
- Spans personalizados para todas las operaciones principales (descarga, parsing, guardado)
- Captura de metadatos: tama√±os de archivos, conteo de art√≠culos, tiempos de ejecuci√≥n, errores
- **Verificaci√≥n autom√°tica**: Verifica si Phoenix es alcanzable antes del procesamiento
- **Degradaci√≥n elegante**: Si Phoenix no est√° disponible, muestra una advertencia pero contin√∫a el procesamiento (las trazas no se recolectar√°n)

##### Configuraci√≥n

El tracing de Phoenix se configura mediante argumentos de l√≠nea de comandos con valores por defecto sensatos:

```bash
# Usar configuraci√≥n por defecto de Phoenix (localhost)
uv run extract_law_text.py

# Endpoint personalizado de Phoenix
uv run extract_law_text.py --phoenix-endpoint http://localhost:6006/v1/traces

# Nombre de proyecto personalizado de Phoenix
uv run extract_law_text.py --phoenix-project-name mi-proyecto

# Ambas configuraciones personalizadas de Phoenix
uv run extract_law_text.py --phoenix-endpoint https://tu-instancia.phoenix.arize.com/v1/traces --phoenix-project-name mi-proyecto
```

#### **Uso**

1. Iniciar Phoenix (local):
   ```bash
   cd ../../services/monitoring
   docker-compose up -d
   ```

2. Ejecutar el script normalmente (el tracing es autom√°tico):
   ```bash
   uv run extract_law_text.py --mode local
   ```

3. Ver las trazas en: http://localhost:6006

#### **Sistema de Logging**

El script implementa un sistema de logging separado que distingue entre mensajes del proceso principal y mensajes de Phoenix/debug:

**Logs del Proceso Principal:**
```
10:30:15 [PROCESO] üîÑ Iniciando procesamiento en modo: LOCAL
10:30:15 [PROCESO] üîÑ Descargando desde: https://example.com/ley
10:30:16 [PROCESO] ‚úÖ P√°gina descargada y guardada en: data/raw/ley.html
10:30:16 [PROCESO] ‚úÖ Contenido de la Ley extra√≠do exitosamente
10:30:17 [PROCESO] ‚úÖ Guardado localmente: data/processed/articulos.json
10:30:17 [PROCESO] üìä Art√≠culos totales: 150
10:30:17 [PROCESO] ‚úÖ Proceso completado exitosamente!
```

**Logs de Phoenix/Debug:**
```
10:30:15 [PHOENIX] Phoenix tracing inicializado correctamente
10:30:15 [PHOENIX] Sesi√≥n creada: 550e8400-e29b-41d4-a716-446655440000
10:30:15 [PHOENIX] Iniciando span Phoenix: download_law_page (kind: CLIENT) [Sesi√≥n: 550e8400]
10:30:16 [PHOENIX] Finalizando span Phoenix: download_law_page
10:30:17 [PHOENIX] Sesi√≥n finalizada: 550e8400-e29b-41d4-a716-446655440000
```

**Control de Nivel de Logging:**

```bash
# Ver todos los logs de Phoenix (debug completo)
uv run extract_law_text.py --phoenix-log-level DEBUG

# Solo informaci√≥n importante de Phoenix (por defecto)
uv run extract_law_text.py --phoenix-log-level INFO

# Solo warnings y errores de Phoenix
uv run extract_law_text.py --phoenix-log-level WARNING

# Solo errores cr√≠ticos de Phoenix
uv run extract_law_text.py --phoenix-log-level ERROR
```

**Beneficios:**
- **Separaci√≥n clara**: Proceso principal vs debugging/tracing
- **Control granular**: Ajustar nivel de verbosidad de Phoenix
- **Formato profesional**: Timestamps y categorizaci√≥n consistente
- **F√°cil filtrado**: Identificar r√°pidamente mensajes importantes

### **Notas Importantes**

- **Trazado siempre activo**: El script siempre intenta enviar trazas
- **Verificaci√≥n de Phoenix**: Antes del procesamiento, el script verifica si Phoenix es alcanzable
- **Advertencia si no disponible**: Si Phoenix no est√° ejecut√°ndose, ver√°s advertencias pero el procesamiento continuar√°
- **Sin p√©rdida de datos**: Si Phoenix se vuelve disponible durante la ejecuci√≥n, las trazas se enviar√°n
- El modo GCS crea directorios temporales que se limpian autom√°ticamente al finalizar
- Para el modo GCS, aseg√∫rate de tener permisos de escritura en el bucket especificado
- El script maneja errores de red y de procesamiento de manera robusta
- Los archivos temporales se crean con el prefijo `lus_laboris_` para facilitar la identificaci√≥n