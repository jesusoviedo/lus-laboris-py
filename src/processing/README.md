<div align="center">

**Language / Idioma:**
[ðŸ‡ºðŸ‡¸ English](#legal-text-processing) | [ðŸ‡ªðŸ‡¸ EspaÃ±ol](#procesamiento-de-texto-legal)

</div>

---

# Legal Text Processing

This directory contains scripts for extracting and processing text from Paraguay's Labor Code.

## Available Scripts

### `extract_law_text.py`

Main script for extracting and processing text from Paraguay's Labor Code from its official source.

#### Features

- **Two execution modes**:
  - **Local**: Saves files to local filesystem
  - **GCS**: Creates temporary folders and uploads JSON to Google Cloud Storage

- **Functionalities**:
  - Automatic HTML download from official site
  - Text extraction and cleaning
  - Structured article segmentation
  - Quality validation and reporting
  - JSON format saving
  - Phoenix/OpenTelemetry tracing for observability (always enabled)

#### Dependencies Installation

- See the [UV documentation](https://github.com/astral-sh/uv) for more details.

```bash
# Install dependencies using uv
uv sync
```

#### Usage

##### Local Mode (default)

```bash
# Basic execution
uv run extract_law_text.py

# Custom filenames
uv run extract_law_text.py --raw-filename mylaw.html --processed-filename myoutput.json

# Skip quality validation for faster processing
uv run extract_law_text.py --skip-quality-validation
```

- The raw HTML will be saved to `data/raw/{raw-filename}` (default: `codigo_trabajo_py.html`) in the project root (not the current directory).
- The processed JSON will be saved to `data/processed/{processed-filename}` (default: `codigo_trabajo_articulos.json`) in the project root.

#### Quality Validation

The script automatically validates processed data quality by:
- **Structure validation**: Checks required fields and valid article numbers (1-413)
- **Completeness verification**: Ensures all 413 articles are present without duplicates
- **Content analysis**: Analyzes article length, special characters, and content quality
- **Comprehensive reporting**: Generates detailed quality reports with metrics and status

Use `--skip-quality-validation` to disable validation for faster processing.

##### Google Cloud Storage Mode

```bash
# Basic GCS execution
uv run extract_law_text.py --mode gcs --bucket-name my-bucket

# Use local credentials (for local development)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --use-local-credentials
```

- The raw HTML will always be uploaded to `raw/{raw-filename}` in the bucket (default: `codigo_trabajo_py.html`).
- The processed JSON will always be uploaded to `processed/{processed-filename}` in the bucket (default: `codigo_trabajo_articulos.json`).

#### Command Line Arguments

| Argument             | Description                                         | Required           | Default                        |
|---------------------|-----------------------------------------------------|--------------------|--------------------------------|
| `--mode`             | Execution mode: `local` or `gcs`                    | No                 | `local`                         |
| `--url`              | Law page URL                                        | No                 | Official URL                    |
| `--bucket-name`      | GCS bucket name (gcs mode)                          | Yes (for gcs mode) | -                               |
| `--raw-filename`     | Name for raw HTML file                              | No                 | `codigo_trabajo_py.html`        |
| `--processed-filename`| Name for processed JSON file                        | No                 | `codigo_trabajo_articulos.json` |
| `--use-local-credentials`| Force use of local credentials file (for local dev, not Cloud Run) | No                 | False                           |
| `--gcp-credentials-dir` | Path to the folder where the GCP .json credentials file is located (optional, useful for Docker) | No | Project root `.gcpcredentials` |
| `--output-root`        | Root directory for local output (data/raw and data/processed) (optional, useful for Docker) | No | Project root |
| `--phoenix-endpoint`   | Phoenix endpoint URL for tracing                    | No                 | `http://localhost:6006/v1/traces` |
| `--phoenix-project-name`| Phoenix project name for tracing                   | No                 | `lus-laboris-processing` |
| `--phoenix-log-level`  | Phoenix logging level (DEBUG/INFO/WARNING/ERROR)   | No                 | `INFO` |
| `--skip-quality-validation` | Skip quality validation and reporting | No | False |

#### Docker Usage

The script can be run using Docker with custom Phoenix configuration:

```bash
# Build the Docker image
docker build -t lus-laboris-processing .

# Run with default Phoenix configuration
docker run --rm lus-laboris-processing

# Run with custom Phoenix endpoint
docker run --rm lus-laboris-processing --phoenix-endpoint http://host.docker.internal:6006/v1/traces

# Run with custom Phoenix project name
docker run --rm lus-laboris-processing --phoenix-project-name my-docker-project

# Run in GCS mode with custom Phoenix settings
docker run --rm -e GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json \
  -v /path/to/credentials.json:/app/credentials.json:ro \
  lus-laboris-processing --mode gcs --bucket-name my-bucket \
  --phoenix-endpoint http://host.docker.internal:6006/v1/traces \
  --phoenix-project-name my-docker-project
```

**Note:** When using Docker, use `host.docker.internal` instead of `localhost` to connect to Phoenix running on the host machine.

#### Google Cloud Storage Configuration

To use GCS mode, you need to configure authentication:

- By default (recommended for Cloud Run), the script will use the environment's credentials (e.g., Cloud Run's default Service Account).
- If you use the `--use-local-credentials` flag, the script will look for a service account `.json` file in a `.gcpcredentials` folder at the project root and set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable automatically. This is useful for local development.
- You can override the credentials folder location with the `--gcp-credentials-dir` flag (recommended for Docker).

#### Phoenix Tracing

The script includes built-in support for Phoenix/OpenTelemetry tracing to monitor execution and performance. **Tracing is always enabled** when you run the script.

> **For detailed Phoenix setup and advanced features, see the [Phoenix Guide](../../docs/phoenix_guide.md)**

**Features:**
- Automatic HTTP request instrumentation
- Custom spans for all major operations (download, parsing, saving)
- Captures metadata: file sizes, article counts, execution times, errors
- **Automatic verification**: Checks if Phoenix is reachable before processing
- **Graceful degradation**: If Phoenix is unavailable, shows a warning but continues processing (traces won't be collected)

**Configuration:**

Phoenix tracing is configured via command-line arguments with sensible defaults:

```bash
# Use default Phoenix configuration (localhost)
uv run extract_law_text.py

# Custom Phoenix endpoint
uv run extract_law_text.py --phoenix-endpoint http://localhost:6006/v1/traces

# Custom Phoenix project name
uv run extract_law_text.py --phoenix-project-name my-project

# Both custom Phoenix settings
uv run extract_law_text.py --phoenix-endpoint https://your-instance.phoenix.arize.com/v1/traces --phoenix-project-name my-project
```

**Phoenix Arguments:**

| Argument | Description | Default | Required |
|----------|-------------|---------|----------|
| `--phoenix-endpoint` | Phoenix endpoint URL for sending traces | `http://localhost:6006/v1/traces` | No |
| `--phoenix-project-name` | Phoenix project name for traces | `lus-laboris-processing` | No |

**Usage:**

1. Start Phoenix (local):
   ```bash
   cd ../../services/monitoring
   docker-compose up -d
   ```

2. Run the script normally (tracing is automatic):
   ```bash
   uv run extract_law_text.py --mode local
   ```

3. View traces at: http://localhost:6006

**Important Notes:**
- **Tracing is always active**: The script always attempts to send traces
- **Phoenix verification**: Before processing, the script checks if Phoenix is reachable
- **Warning if unavailable**: If Phoenix is not running, you'll see warnings but processing continues
- **No data loss**: If Phoenix becomes available during execution, traces will be sent

#### Separate Logging System

The script implements a separate logging system that distinguishes between main process messages and Phoenix/debug messages:

**Main Process Logs:**
```
10:30:15 [PROCESO] ðŸ”„ Starting processing in mode: LOCAL
10:30:15 [PROCESO] ðŸ”„ Downloading from: https://example.com/ley
10:30:16 [PROCESO] âœ… Page downloaded and saved to: data/raw/ley.html
10:30:16 [PROCESO] âœ… Law content extracted successfully
10:30:17 [PROCESO] âœ… Saved locally: data/processed/articulos.json
10:30:17 [PROCESO] ðŸ“Š Total articles: 150
10:30:17 [PROCESO] âœ… Process completed successfully!
```

**Phoenix/Debug Logs:**
```
10:30:15 [PHOENIX] Phoenix tracing initialized correctly
10:30:15 [PHOENIX] Session created: 550e8400-e29b-41d4-a716-446655440000
10:30:15 [PHOENIX] Starting Phoenix span: download_law_page (kind: CLIENT) [Session: 550e8400]
10:30:16 [PHOENIX] Ending Phoenix span: download_law_page
10:30:17 [PHOENIX] Session ended: 550e8400-e29b-41d4-a716-446655440000
```

**Log Level Control:**

```bash
# See all Phoenix logs (full debug)
uv run extract_law_text.py --phoenix-log-level DEBUG

# Only important Phoenix information (default)
uv run extract_law_text.py --phoenix-log-level INFO

# Only Phoenix warnings and errors
uv run extract_law_text.py --phoenix-log-level WARNING

# Only critical Phoenix errors
uv run extract_law_text.py --phoenix-log-level ERROR
```

**Benefits:**
- **Clear separation**: Main process vs debugging/tracing
- **Granular control**: Adjust Phoenix verbosity level
- **Professional format**: Consistent timestamps and categorization
- **Easy filtering**: Quickly identify important messages

#### Output Structure

The script generates a JSON file with the following structure:

```json
{
  "meta": {
    "numero_ley": "213",
    "fecha_promulgacion": "DD-MM-YYYY",
    "fecha_publicacion": "DD-MM-YYYY"
  },
  "articulos": [
    {
      "articulo_numero": 1,
      "libro": "libro primero",
      "libro_numero": 1,
      "titulo": "tÃ­tulo i",
      "capitulo": "capÃ­tulo i",
      "capitulo_numero": 1,
      "capitulo_descripcion": "chapter description",
      "articulo": "article content..."
    }
  ]
}
```

#### Complete Usage Examples

```bash
# Help
uv run extract_law_text.py --help

# Local mode
uv run extract_law_text.py

# Local mode with custom output root (e.g., for Docker volume)
uv run extract_law_text.py --output-root /app

# Local mode with custom filenames
uv run extract_law_text.py --raw-filename ley.html --processed-filename salida.json

# GCS mode (Cloud Run or default credentials)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket

# GCS mode with local credentials (for local development)
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --use-local-credentials

# GCS mode with custom filenames
uv run extract_law_text.py --mode gcs --bucket-name my-bucket --raw-filename ley.html --processed-filename salida.json
```

#### Important Notes

- GCS mode creates temporary directories that are automatically cleaned up when finished
- For GCS mode, ensure you have write permissions to the specified bucket
- The script handles network and processing errors robustly
- Temporary files are created with the `lus_laboris_` prefix for easy identification

#### Docker Usage

You can build and run the script in a Docker container for maximum portability. See [docker_guide.md](../../docs/docker_guide.md) for more details.

**Build the image:**
```bash
docker build -t labor-law-extractor .
```

**Docker Usage - Local Mode**

You can also run the script in local mode and persist output to a mounted volume:

```bash
# Get the absolute path to the data folder
DATA_DIR=$(realpath ../../data)

docker run --rm \
  -v "${DATA_DIR}:/app/data" \
  labor-law-extractor \
  uv run extract_law_text.py --output-root /app
```

This will save all output in your local 'data' folder.

**Docker Usage - GCS Mode (mounting credentials):**

```bash
# Get the absolute path to the GCP credentials folder
GCP_CREDS=$(realpath ../../.gcpcredentials)

docker run --rm \
  -v "${GCP_CREDS}:/gcpcreds:ro" \
  labor-law-extractor \
  uv run extract_law_text.py \
    --mode gcs \
    --bucket-name py-labor-law-rag-bucket \
    --use-local-credentials \
    --gcp-credentials-dir /gcpcreds
```

This allows you to run the script in GCS mode from Docker, mounting the GCP credentials securely.

#### Publish Docker Image to Docker Hub

You can upload the generated Docker image to Docker Hub manually or automatically.

##### Manual method

1. Load the environment variables from the `.env` file located at the project root (run this from the `src/processing` folder):
```bash
set -o allexport
source ../../.env
set +o allexport
```

2. Make sure you have a `.env` file at the project root with the variables:
   - `DOCKER_HUB_USERNAME`
   - `DOCKER_HUB_PASSWORD`
   - `DOCKER_IMAGE_NAME_PROCESSING`

3. Build the Docker image:
```bash
docker build -t "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" .
```

4. Log in to Docker Hub:
```bash
echo "$DOCKER_HUB_PASSWORD" | docker login --username "$DOCKER_HUB_USERNAME" --password-stdin
```

5. Tag the image with the date:
```bash
DATE_TAG=$(date +%Y%m%d)
docker tag "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

6. Push both tags:
```bash
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest"
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

> **Note:** The script and commands generate two tags: one with `latest` and one with the current date (`YYYYMMDD`).
> **Best practice:** In production, always use the date tag (`YYYYMMDD`) to avoid running unexpected versions that may be under the `latest` tag.

For more details about Docker usage (including Compose and Hub), see the guide:
- [docker_guide.md](../../docs/docker_guide.md)

##### Automatic method (recommended)

You can use the `docker_build_push.sh` script to automate the entire process. The script looks for the `.env` file at the project root (two levels above the `processing` folder).

```bash
bash docker_build_push.sh
```

The script will validate the required variables, build the image, tag it, and push it to Docker Hub with both tags. For more information, see:
- [docker_guide.md](../../docs/docker_guide.md)

---

# Procesamiento de Texto Legal

Este directorio contiene scripts para extraer y procesar texto del CÃ³digo Laboral de Paraguay.

## Scripts Disponibles

### `extract_law_text.py`

Script principal para extraer y procesar el texto del CÃ³digo Laboral de Paraguay desde su fuente oficial.

#### CaracterÃ­sticas

- **Dos modos de ejecuciÃ³n**:
  - **Local**: Guarda archivos en el sistema de archivos local
  - **GCS**: Crea carpetas temporales y sube el JSON a Google Cloud Storage

- **Funcionalidades**:
  - Descarga automÃ¡tica del HTML desde el sitio oficial
  - ExtracciÃ³n y limpieza del texto
  - SegmentaciÃ³n en artÃ­culos estructurados
  - ValidaciÃ³n de calidad y reportes
  - Guardado en formato JSON
  - Trazas Phoenix/OpenTelemetry para observabilidad (siempre activo)

#### InstalaciÃ³n de Dependencias

- Consulta la [documentaciÃ³n de UV](https://github.com/astral-sh/uv) para mÃ¡s detalles.

```bash
# Instalar dependencias usando uv
uv sync
```

#### Uso

##### Modo Local (por defecto)

```bash
# EjecuciÃ³n bÃ¡sica
uv run extract_law_text.py

# Personalizando nombres de archivos
uv run extract_law_text.py --raw-filename mi_ley.html --processed-filename salida.json

# Omitir validaciÃ³n de calidad para procesamiento mÃ¡s rÃ¡pido
uv run extract_law_text.py --skip-quality-validation
```

- El HTML crudo se guardarÃ¡ en `data/raw/{raw-filename}` (por defecto: `codigo_trabajo_py.html`) en la raÃ­z del proyecto (no en el directorio actual).
- El JSON procesado se guardarÃ¡ en `data/processed/{processed-filename}` (por defecto: `codigo_trabajo_articulos.json`) en la raÃ­z del proyecto.

#### ValidaciÃ³n de Calidad

El script valida automÃ¡ticamente la calidad de los datos procesados mediante:
- **ValidaciÃ³n de estructura**: Verifica campos requeridos y nÃºmeros de artÃ­culo vÃ¡lidos (1-413)
- **VerificaciÃ³n de completitud**: Asegura que los 413 artÃ­culos estÃ©n presentes sin duplicados
- **AnÃ¡lisis de contenido**: Analiza longitud de artÃ­culos, caracteres especiales y calidad del contenido
- **Reportes comprensivos**: Genera reportes detallados de calidad con mÃ©tricas y estado

Usa `--skip-quality-validation` para deshabilitar la validaciÃ³n y procesar mÃ¡s rÃ¡pido.

##### Modo Google Cloud Storage

```bash
# EjecuciÃ³n bÃ¡sica con GCS
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket

# Forzar uso de credenciales locales (para desarrollo local)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --use-local-credentials
```

- El HTML crudo siempre se subirÃ¡ a `raw/{raw-filename}` en el bucket (por defecto: `codigo_trabajo_py.html`).
- El JSON procesado siempre se subirÃ¡ a `processed/{processed-filename}` en el bucket (por defecto: `codigo_trabajo_articulos.json`).

#### Argumentos de LÃ­nea de Comandos

| Argumento             | DescripciÃ³n                                         | Requerido           | Por Defecto                    |
|-----------------------|-----------------------------------------------------|---------------------|-------------------------------|
| `--mode`              | Modo de ejecuciÃ³n: `local` o `gcs`                  | No                  | `local`                       |
| `--url`               | URL de la pÃ¡gina de la ley                          | No                  | URL oficial                   |
| `--bucket-name`       | Nombre del bucket de GCS (modo gcs)                 | SÃ­ (para modo gcs)  | -                             |
| `--raw-filename`      | Nombre para el archivo HTML crudo                   | No                  | `codigo_trabajo_py.html`      |
| `--processed-filename`| Nombre para el archivo JSON procesado               | No                  | `codigo_trabajo_articulos.json`|
| `--use-local-credentials`| Forzar uso de credenciales locales (para desarrollo local, no Cloud Run) | No                  | False                         |
| `--gcp-credentials-dir` | Ruta a la carpeta donde buscar el archivo .json de credenciales de GCP (opcional, util para Docker) | No | `.gcpcredentials` en la raÃ­z |
| `--output-root`        | RaÃ­z donde se crearÃ¡n las carpetas data/raw y data/processed en modo local (opcional, Ãºtil para Docker) | No | RaÃ­z del proyecto |
| `--skip-quality-validation` | Omitir validaciÃ³n de calidad y reportes | No | False |

#### Uso con Docker

El script se puede ejecutar usando Docker con configuraciÃ³n personalizada de Phoenix:

```bash
# Construir la imagen Docker
docker build -t lus-laboris-processing .

# Ejecutar con configuraciÃ³n por defecto de Phoenix
docker run --rm lus-laboris-processing

# Ejecutar con endpoint personalizado de Phoenix
docker run --rm lus-laboris-processing --phoenix-endpoint http://host.docker.internal:6006/v1/traces

# Ejecutar con nombre de proyecto personalizado de Phoenix
docker run --rm lus-laboris-processing --phoenix-project-name mi-proyecto-docker

# Ejecutar en modo GCS con configuraciones personalizadas de Phoenix
docker run --rm -e GOOGLE_APPLICATION_CREDENTIALS=/app/credentials.json \
  -v /ruta/a/credentials.json:/app/credentials.json:ro \
  lus-laboris-processing --mode gcs --bucket-name mi-bucket \
  --phoenix-endpoint http://host.docker.internal:6006/v1/traces \
  --phoenix-project-name mi-proyecto-docker
```

**Nota:** Cuando uses Docker, usa `host.docker.internal` en lugar de `localhost` para conectarte a Phoenix ejecutÃ¡ndose en la mÃ¡quina host.

#### ConfiguraciÃ³n para Google Cloud Storage

Para usar el modo GCS, necesitas configurar la autenticaciÃ³n:

- Por defecto (recomendado para Cloud Run), el script usarÃ¡ las credenciales del entorno (por ejemplo, la Service Account por defecto de Cloud Run).
- Si usas el flag `--use-local-credentials`, el script buscarÃ¡ automÃ¡ticamente un archivo `.json` de cuenta de servicio en la carpeta `.gcpcredentials` en la raÃ­z del proyecto y establecerÃ¡ la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS`. Esto es Ãºtil para desarrollo local.
- Puedes sobrescribir la ubicaciÃ³n de la carpeta de credenciales con el flag `--gcp-credentials-dir` (recomendado para Docker).

#### Trazas Phoenix

El script incluye soporte integrado para trazas Phoenix/OpenTelemetry para monitorear la ejecuciÃ³n y rendimiento. **El trazado siempre estÃ¡ activo** cuando ejecutas el script.

> **Para configuraciÃ³n detallada de Phoenix y caracterÃ­sticas avanzadas, consulta la [GuÃ­a de Phoenix](../../docs/phoenix_guide.md)**

**CaracterÃ­sticas:**
- InstrumentaciÃ³n automÃ¡tica de peticiones HTTP
- Spans personalizados para todas las operaciones principales (descarga, parsing, guardado)
- Captura de metadatos: tamaÃ±os de archivos, conteo de artÃ­culos, tiempos de ejecuciÃ³n, errores
- **VerificaciÃ³n automÃ¡tica**: Verifica si Phoenix es alcanzable antes del procesamiento
- **DegradaciÃ³n elegante**: Si Phoenix no estÃ¡ disponible, muestra una advertencia pero continÃºa el procesamiento (las trazas no se recolectarÃ¡n)

**ConfiguraciÃ³n:**

El tracing de Phoenix se configura mediante argumentos de lÃ­nea de comandos con valores por defecto sensatos:

```bash
# Usar configuraciÃ³n por defecto de Phoenix (localhost)
uv run extract_law_text.py

# Endpoint personalizado de Phoenix
uv run extract_law_text.py --phoenix-endpoint http://localhost:6006/v1/traces

# Nombre de proyecto personalizado de Phoenix
uv run extract_law_text.py --phoenix-project-name mi-proyecto

# Ambas configuraciones personalizadas de Phoenix
uv run extract_law_text.py --phoenix-endpoint https://tu-instancia.phoenix.arize.com/v1/traces --phoenix-project-name mi-proyecto
```

**Argumentos de Phoenix:**

| Argumento | DescripciÃ³n | Por Defecto | Requerido |
|-----------|-------------|-------------|-----------|
| `--phoenix-endpoint` | URL del endpoint de Phoenix para enviar trazas | `http://localhost:6006/v1/traces` | No |
| `--phoenix-project-name` | Nombre del proyecto para las trazas de Phoenix | `lus-laboris-processing` | No |
| `--phoenix-log-level` | Nivel de logging de Phoenix (DEBUG/INFO/WARNING/ERROR) | `INFO` | No |

**Uso:**

1. Iniciar Phoenix (local):
   ```bash
   cd ../../services/monitoring
   docker-compose up -d
   ```

2. Ejecutar el script normalmente (el tracing es automÃ¡tico):
   ```bash
   uv run extract_law_text.py --mode local
   ```

3. Ver las trazas en: http://localhost:6006

**Notas Importantes:**
- **Trazado siempre activo**: El script siempre intenta enviar trazas
- **VerificaciÃ³n de Phoenix**: Antes del procesamiento, el script verifica si Phoenix es alcanzable
- **Advertencia si no disponible**: Si Phoenix no estÃ¡ ejecutÃ¡ndose, verÃ¡s advertencias pero el procesamiento continuarÃ¡
- **Sin pÃ©rdida de datos**: Si Phoenix se vuelve disponible durante la ejecuciÃ³n, las trazas se enviarÃ¡n

#### Sistema de Logging Separado

El script implementa un sistema de logging separado que distingue entre mensajes del proceso principal y mensajes de Phoenix/debug:

**Logs del Proceso Principal:**
```
10:30:15 [PROCESO] ðŸ”„ Iniciando procesamiento en modo: LOCAL
10:30:15 [PROCESO] ðŸ”„ Descargando desde: https://example.com/ley
10:30:16 [PROCESO] âœ… PÃ¡gina descargada y guardada en: data/raw/ley.html
10:30:16 [PROCESO] âœ… Contenido de la Ley extraÃ­do exitosamente
10:30:17 [PROCESO] âœ… Guardado localmente: data/processed/articulos.json
10:30:17 [PROCESO] ðŸ“Š ArtÃ­culos totales: 150
10:30:17 [PROCESO] âœ… Proceso completado exitosamente!
```

**Logs de Phoenix/Debug:**
```
10:30:15 [PHOENIX] Phoenix tracing inicializado correctamente
10:30:15 [PHOENIX] SesiÃ³n creada: 550e8400-e29b-41d4-a716-446655440000
10:30:15 [PHOENIX] Iniciando span Phoenix: download_law_page (kind: CLIENT) [SesiÃ³n: 550e8400]
10:30:16 [PHOENIX] Finalizando span Phoenix: download_law_page
10:30:17 [PHOENIX] SesiÃ³n finalizada: 550e8400-e29b-41d4-a716-446655440000
```

**Control de Nivel de Logging:**

```bash
# Ver todos los logs de Phoenix (debug completo)
uv run extract_law_text.py --phoenix-log-level DEBUG

# Solo informaciÃ³n importante de Phoenix (por defecto)
uv run extract_law_text.py --phoenix-log-level INFO

# Solo warnings y errores de Phoenix
uv run extract_law_text.py --phoenix-log-level WARNING

# Solo errores crÃ­ticos de Phoenix
uv run extract_law_text.py --phoenix-log-level ERROR
```

**Beneficios:**
- **SeparaciÃ³n clara**: Proceso principal vs debugging/tracing
- **Control granular**: Ajustar nivel de verbosidad de Phoenix
- **Formato profesional**: Timestamps y categorizaciÃ³n consistente
- **FÃ¡cil filtrado**: Identificar rÃ¡pidamente mensajes importantes

#### Estructura de Salida

El script genera un archivo JSON con la siguiente estructura:

```json
{
  "meta": {
    "numero_ley": "213",
    "fecha_promulgacion": "DD-MM-YYYY",
    "fecha_publicacion": "DD-MM-YYYY"
  },
  "articulos": [
    {
      "articulo_numero": 1,
      "libro": "libro primero",
      "libro_numero": 1,
      "titulo": "tÃ­tulo i",
      "capitulo": "capÃ­tulo i",
      "capitulo_numero": 1,
      "capitulo_descripcion": "descripciÃ³n del capÃ­tulo",
      "articulo": "contenido del artÃ­culo..."
    }
  ]
}
```

#### Ejemplos de Uso Completos

```bash
# Ayuda
uv run extract_law_text.py --help

# Modo local
uv run extract_law_text.py

# Modo local con raÃ­z de salida personalizada (por ejemplo, para volumen Docker)
uv run extract_law_text.py --output-root /app

# Modo local con nombres personalizados
uv run extract_law_text.py --raw-filename ley.html --processed-filename salida.json

# Modo GCS (Cloud Run o credenciales por defecto)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket

# Modo GCS con credenciales locales (para desarrollo local)
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --use-local-credentials

# Modo GCS con nombres personalizados
uv run extract_law_text.py --mode gcs --bucket-name mi-bucket --raw-filename ley.html --processed-filename salida.json
```

#### Notas Importantes

- El modo GCS crea directorios temporales que se limpian automÃ¡ticamente al finalizar
- Para el modo GCS, asegÃºrate de tener permisos de escritura en el bucket especificado
- El script maneja errores de red y de procesamiento de manera robusta
- Los archivos temporales se crean con el prefijo `lus_laboris_` para facilitar la identificaciÃ³n

#### Uso con Docker

Puedes construir y ejecutar el script en un contenedor Docker para mÃ¡xima portabilidad. Consulta [docker_guide.md](../../docs/docker_guide.md) para mÃ¡s detalles.

**Construir la imagen:**
```bash
docker build -t labor-law-extractor .
```

**Uso con Docker - Modo Local**

Puedes ejecutar el script en modo local y persistir la salida en un volumen montado:

```bash
# Obtener la ruta absoluta de la carpeta data
DATA_DIR=$(realpath ../../data)

docker run --rm \
  -v "${DATA_DIR}:/app/data" \
  labor-law-extractor \
  uv run extract_law_text.py --output-root /app
```

Esto guardarÃ¡ toda la salida en tu carpeta local 'data'.

**Uso con Docker - Modo GCS (montando credenciales):**

```bash
# Obtener la ruta absoluta de la carpeta de credenciales GCP
GCP_CREDS=$(realpath ../../.gcpcredentials)

docker run --rm \
  -v "${GCP_CREDS}:/gcpcreds:ro" \
  labor-law-extractor \
  uv run extract_law_text.py \
    --mode gcs \
    --bucket-name py-labor-law-rag-bucket \
    --use-local-credentials \
    --gcp-credentials-dir /gcpcreds
```

Esto permite ejecutar el script en modo GCS desde Docker, montando las credenciales de GCP de forma segura.

#### Publicar imagen en Docker Hub

Puedes subir la imagen Docker generada a Docker Hub de forma manual o automÃ¡tica.

##### MÃ©todo manual

1. Carga las variables de entorno desde el archivo `.env` ubicado en la raÃ­z del proyecto (ejecuta esto desde la carpeta `src/processing`):
```bash
set -o allexport
source ../../.env
set +o allexport
```

2. AsegÃºrate de tener un archivo `.env` en la raÃ­z del proyecto con las variables:
   - `DOCKER_HUB_USERNAME`
   - `DOCKER_HUB_PASSWORD`
   - `DOCKER_IMAGE_NAME_PROCESSING`

3. Construye la imagen Docker:
```bash
docker build -t "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" .
```

4. Inicia sesiÃ³n en Docker Hub:
```bash
echo "$DOCKER_HUB_PASSWORD" | docker login --username "$DOCKER_HUB_USERNAME" --password-stdin
```

5. Etiqueta la imagen con la fecha:
```bash
DATE_TAG=$(date +%Y%m%d)
docker tag "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest" "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

6. Sube ambas etiquetas:
```bash
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:latest"
docker push "$DOCKER_HUB_USERNAME/$DOCKER_IMAGE_NAME_PROCESSING:$DATE_TAG"
```

> **Nota:** El script y los comandos generan dos tags: uno con la palabra `latest` y otro con la fecha actual (formato `YYYYMMDD`).
> **Buena prÃ¡ctica:** En producciÃ³n, siempre utiliza el tag de fecha (`YYYYMMDD`) para evitar ejecutar versiones inesperadas que puedan estar bajo el tag `latest`.

Para mÃ¡s detalles sobre el uso de Docker (incluyendo Compose y Hub), consulta la guÃ­a:
- [docker_guide.md](../../docs/docker_guide.md)

##### MÃ©todo automÃ¡tico (recomendado)

Puedes usar el script `docker_build_push.sh` que automatiza todo el proceso. El script busca el archivo `.env` en la raÃ­z del proyecto (dos niveles arriba de la carpeta `processing`).

```bash
bash docker_build_push.sh
```

El script validarÃ¡ las variables necesarias, construirÃ¡ la imagen, la etiquetarÃ¡ y la subirÃ¡ a Docker Hub con los tags correspondientes. Para mÃ¡s informaciÃ³n, revisa:
- [docker_guide.md](../../docs/docker_guide.md)