# Phoenix Guide

<div align="center">

**Language / Idioma:**
[üá∫üá∏ English](#phoenix-guide) | [üá™üá∏ Espa√±ol](#gu√≠a-de-phoenix)

</div>

---

# Phoenix Guide

This guide provides comprehensive instructions for setting up and using Phoenix for real-time observability and evaluation of the RAG system. Phoenix is an open-source observability platform designed specifically for LLM applications.

## Table of Contents

- [Overview](#overview)
- [Prerequisites](#prerequisites)
- [Local Setup](#local-setup)
- [Configuration](#configuration)
- [Integration with RAG API](#integration-with-rag-api)
- [Advanced Tracing Features](#advanced-tracing-features)
- [Session Management](#session-management)
- [Span Kinds and Categorization](#span-kinds-and-categorization)
- [Monitoring Features](#monitoring-features)
- [Production Deployment](#production-deployment)
- [Troubleshooting](#troubleshooting)

## Overview

Phoenix provides real-time observability for LLM applications, offering:

- **Trace Analysis**: Detailed tracing of requests through the RAG pipeline
- **Performance Metrics**: Response times, token usage, and accuracy tracking
- **LLM Monitoring**: OpenAI and Gemini API usage and performance
- **Evaluation Metrics**: Retrieval and generation quality metrics
- **Real-time Dashboard**: Interactive UI for monitoring and analysis

## Prerequisites

- Docker and Docker Compose installed
- Python 3.13+ environment
- Access to the project's `.env` file
- Basic understanding of observability concepts

## Local Setup

### 1. Navigate to Phoenix Directory

```bash
cd services/monitoring
```

### 2. Start Phoenix with Docker Compose

```bash
# Start Phoenix in detached mode
docker-compose up -d

# Check if Phoenix is running
docker-compose ps

# View logs
docker-compose logs -f phoenix
```

### 3. Verify Installation

```bash
# Check Phoenix health
curl http://localhost:6006/health

# Access the Phoenix UI
open http://localhost:6006
```

## Configuration

### Environment Variables

Add the following variables to your `.env` file in the project root:

```env
# Phoenix Configuration
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6006/v1/traces
PHOENIX_GRPC_ENDPOINT=localhost:4317

# Instrumentation Settings
INSTRUMENT_OPENAI=true
INSTRUMENT_GEMINI=true
INSTRUMENT_LLAMA_INDEX=true

# Optional: Prometheus metrics
PHOENIX_PROMETHEUS_ENABLED=true
PHOENIX_PROMETHEUS_PORT=9090
```

### Docker Compose Configuration

The `docker-compose.yml` file includes:

```yaml
services:
  phoenix:
    image: arizephoenix/phoenix:latest
    ports:
      - "6006:6006"  # UI and OTLP HTTP collector
      - "4317:4317"  # OTLP gRPC collector
      - "9090:9090"  # Prometheus metrics (optional)
    environment:
      - PHOENIX_WORKING_DIR=/mnt/data
    volumes:
      - phoenix_data:/mnt/data
    env_file:
      - ../../.env
```

## Integration with RAG API

### 1. Install Phoenix Python Package

```bash
# Add to your pyproject.toml
phoenix = "^4.0.0"
```

### 2. Basic Instrumentation

```python
# In your RAG service
import phoenix as px
from phoenix.trace import trace

class RAGService:
    @trace
    def answer_question(self, question: str):
        # Your existing RAG code
        # Phoenix will automatically capture metrics
        pass
```

### 3. Advanced Instrumentation

```python
# Custom tracing for specific operations
from phoenix.trace import trace, set_attributes

@trace
def retrieve_documents(self, query: str):
    with trace("embedding_generation"):
        embedding = self.embedding_service.generate_embedding(query)

    with trace("vector_search"):
        results = self.qdrant_service.search(embedding)

    set_attributes({
        "query_length": len(query),
        "results_count": len(results),
        "search_time": time.time() - start_time
    })

    return results
```

## Advanced Tracing Features

The law processing system includes advanced Phoenix tracing features for comprehensive observability:

### Context Managers vs Decorators

The system uses **context managers** instead of decorators for better control and granular tracing:

```python
from opentelemetry.trace import SpanKind

# Using context manager for custom spans
with phoenix_span("operation_name", SpanKind.INTERNAL, {"param": "value"}):
    # Your operation code here
    pass
```

### Automatic Session Grouping

All spans from a single execution are automatically grouped under a session with unique identifiers.

## Session Management

The system implements automatic session management to group all spans from a single execution:

### Session Features

- **Unique Session ID**: Each execution gets a UUID for identification
- **Automatic Grouping**: All spans are grouped under a root session span
- **Session Attributes**: Each span includes session information
- **Duration Tracking**: Total execution time is tracked at session level

### Session Structure

```text
execution_session (SERVER) üîµ [ROOT SESSION]
‚îú‚îÄ‚îÄ session.id: "550e8400-e29b-41d4-a716-446655440000"
‚îú‚îÄ‚îÄ session.start_time: "2024-01-15T10:30:00.123456"
‚îú‚îÄ‚îÄ session.type: "law_processing"
‚îú‚îÄ‚îÄ session.version: "1.0"
‚îÇ
‚îî‚îÄ‚îÄ main_process (SERVER) üîµ [CHILD OF SESSION]
    ‚îú‚îÄ‚îÄ session.id: "550e8400-e29b-41d4-a716-446655440000"
    ‚îú‚îÄ‚îÄ execution.timestamp: "2024-01-15T10:30:00.234567"
    ‚îÇ
    ‚îî‚îÄ‚îÄ All operation spans with session.id attribute
```

### Session Benefits

1. **Visual Grouping**: All spans from one execution appear grouped in Phoenix
2. **Easy Filtering**: Filter by `session.id` to see specific executions
3. **Performance Analysis**: Compare different executions easily
4. **Complete Traceability**: Track the full lifecycle of each execution

### Using Sessions in Phoenix

**Filter by Session:**

```text
session.id = "550e8400-e29b-41d4-a716-446655440000"
```

**View Session Duration:**

- The root `execution_session` span shows total execution time
- Compare durations across different executions

## Span Kinds and Categorization

The system uses OpenTelemetry Span Kinds for better visualization and categorization:

### Span Kind Types

#### üîµ **SpanKind.SERVER**

**Purpose**: Main operations that coordinate other operations

- `main_process` - Main application process
- `process_law_local` - Complete local processing
- `process_law_gcs` - Complete GCS processing

#### üü¢ **SpanKind.CLIENT**

**Purpose**: Operations that make external calls

- `download_law_page` - Download from external URL

#### üü° **SpanKind.PRODUCER**

**Purpose**: Operations that send data to external systems

- `save_parsed_json_gcs` - Save to Google Cloud Storage
- `upload_file_to_gcs` - Upload files to GCS

#### ‚ö™ **SpanKind.INTERNAL**

**Purpose**: Internal data processing operations

- `extract_metadata` - Extract law metadata
- `extract_articles` - Segment articles
- `parse_law_text` - Process complete text
- `extract_text_from_html` - Extract clean text from HTML
- `save_parsed_json_local` - Save files locally

### Benefits of Span Kinds

1. **Better Visualization**: Different icons and colors for each operation type
2. **Clear Categorization**: Easy identification of operation types
3. **Performance Analysis**: Identify where resources are spent by type
4. **Improved Debugging**: Easier problem identification
5. **Type-specific Metrics**: Generate metrics by operation type

### Span Hierarchy

```text
main_process (SERVER) üîµ
‚îú‚îÄ‚îÄ process_law_local/process_law_gcs (SERVER) üîµ
    ‚îú‚îÄ‚îÄ download_law_page (CLIENT) üü¢
    ‚îú‚îÄ‚îÄ extract_text_from_html (INTERNAL) ‚ö™
    ‚îú‚îÄ‚îÄ parse_law_text (INTERNAL) ‚ö™
    ‚îÇ   ‚îú‚îÄ‚îÄ extract_metadata (INTERNAL) ‚ö™
    ‚îÇ   ‚îî‚îÄ‚îÄ extract_articles (INTERNAL) ‚ö™
    ‚îú‚îÄ‚îÄ save_parsed_json_local (INTERNAL) ‚ö™ [local mode]
    ‚îú‚îÄ‚îÄ upload_file_to_gcs (PRODUCER) üü° [GCS mode]
    ‚îî‚îÄ‚îÄ save_parsed_json_gcs (PRODUCER) üü° [GCS mode]
```

### Attributes by Span Type

**CLIENT Spans:**

- `url` - External call URL
- `output_path` - Local output path

**PRODUCER Spans:**

- `bucket_name` - GCS bucket name
- `filename` - File name
- `articles_count` - Number of processed articles

**INTERNAL Spans:**

- `lines_count` - Number of processed lines
- `text_length` - Text length
- `html_path` - HTML file path
- `articles_count` - Number of extracted articles

**SERVER Spans:**

- `mode` - Operation mode (local/gcs)
- `url` - Law URL
- `bucket_name` - Bucket name (GCS mode only)
- `raw_filename` - HTML filename
- `processed_filename` - JSON filename
- `output_root` - Output root directory (local mode only)
- `use_local_credentials` - Use local credentials (GCS mode only)

## Monitoring Features

### 1. Trace Analysis

Phoenix provides detailed traces showing:

- Request flow through the RAG pipeline
- Time spent in each component
- Token usage and costs
- Error rates and exceptions

### 2. Performance Metrics

Track key performance indicators:

- **Response Time**: End-to-end request processing time
- **Token Usage**: Tokens consumed per request
- **Throughput**: Requests per minute
- **Error Rate**: Percentage of failed requests

### 3. LLM Monitoring

Monitor LLM providers:

- **OpenAI**: API calls, token usage, costs
- **Google Gemini**: API calls, token usage, costs
- **Model Performance**: Response quality and consistency

### 4. Evaluation Metrics

Track RAG system quality:

- **Retrieval Accuracy**: Relevance of retrieved documents
- **Generation Quality**: Response accuracy and coherence
- **Reranking Effectiveness**: Impact of reranking on results

## Production Deployment

### Option 1: Phoenix Cloud (Recommended)

For production, use Phoenix Cloud to avoid infrastructure overhead:

1. **Sign up** at [Phoenix Cloud](https://arize.com/phoenix)
2. **Get API key** from your dashboard
3. **Update environment variables**:

```env
PHOENIX_COLLECTOR_ENDPOINT=https://your-instance.phoenix.arize.com/v1/traces
PHOENIX_API_KEY=your_api_key_here
```

### Option 2: Self-Hosted

For self-hosted deployment, see the [Phoenix documentation](https://arize.com/docs/phoenix/self-hosting/).

## Troubleshooting

### Common Issues

#### Phoenix Won't Start

```bash
# Check Docker status
docker info

# Check port availability
netstat -tulpn | grep :6006

# Restart Phoenix
docker-compose down
docker-compose up -d
```

#### No Traces Appearing

1. **Check environment variables**:

   ```bash
   echo $PHOENIX_COLLECTOR_ENDPOINT
   ```

2. **Verify instrumentation**:

   ```python
   import phoenix as px
   print(px.get_tracer())
   ```

3. **Check network connectivity**:

   ```bash
   curl http://localhost:6006/health
   ```

#### High Memory Usage

```bash
# Monitor resource usage
docker stats phoenix

# Adjust memory limits in docker-compose.yml
services:
  phoenix:
    mem_limit: 2g
```

### Logs and Debugging

```bash
# View Phoenix logs
docker-compose logs phoenix

# Follow logs in real-time
docker-compose logs -f phoenix

# Check specific service logs
docker-compose logs phoenix | grep ERROR
```

## Best Practices

1. **Start with Local Development**: Use local Phoenix for development and testing
2. **Use Phoenix Cloud for Production**: Avoid infrastructure overhead
3. **Instrument Key Operations**: Focus on critical paths in your RAG pipeline
4. **Monitor Resource Usage**: Keep an eye on memory and CPU usage
5. **Set Up Alerts**: Configure alerts for critical metrics
6. **Regular Cleanup**: Clean up old traces to manage storage

---

# Gu√≠a de Phoenix

Esta gu√≠a proporciona instrucciones completas para configurar y usar Phoenix para observabilidad en tiempo real y evaluaci√≥n del sistema RAG. Phoenix es una plataforma de observabilidad de c√≥digo abierto dise√±ada espec√≠ficamente para aplicaciones LLM.

## Tabla de Contenidos

- [Resumen](#resumen)
- [Prerrequisitos](#prerrequisitos)
- [Configuraci√≥n Local](#configuraci√≥n-local)
- [Configuraci√≥n](#configuraci√≥n)
- [Integraci√≥n con API RAG](#integraci√≥n-con-api-rag)
- [Caracter√≠sticas Avanzadas de Tracing](#caracter√≠sticas-avanzadas-de-tracing)
- [Gesti√≥n de Sesiones](#gesti√≥n-de-sesiones)
- [Tipos de Spans y Categorizaci√≥n](#tipos-de-spans-y-categorizaci√≥n)
- [Caracter√≠sticas de Monitoreo](#caracter√≠sticas-de-monitoreo)
- [Despliegue en Producci√≥n](#despliegue-en-producci√≥n)
- [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)

## Resumen

Phoenix proporciona observabilidad en tiempo real para aplicaciones LLM, ofreciendo:

- **An√°lisis de Trazas**: Trazado detallado de solicitudes a trav√©s del pipeline RAG
- **M√©tricas de Rendimiento**: Tiempos de respuesta, uso de tokens y seguimiento de precisi√≥n
- **Monitoreo de LLM**: Uso y rendimiento de APIs de OpenAI y Gemini
- **M√©tricas de Evaluaci√≥n**: M√©tricas de calidad de recuperaci√≥n y generaci√≥n
- **Dashboard en Tiempo Real**: UI interactiva para monitoreo y an√°lisis

## Prerrequisitos

- Docker y Docker Compose instalados
- Entorno Python 3.13+
- Acceso al archivo `.env` del proyecto
- Comprensi√≥n b√°sica de conceptos de observabilidad

## Configuraci√≥n Local

### 1. Navegar al Directorio de Phoenix

```bash
cd services/monitoring
```

### 2. Iniciar Phoenix con Docker Compose

```bash
# Iniciar Phoenix en modo detached
docker-compose up -d

# Verificar si Phoenix est√° ejecut√°ndose
docker-compose ps

# Ver logs
docker-compose logs -f phoenix
```

### 3. Verificar la Instalaci√≥n

```bash
# Verificar salud de Phoenix
curl http://localhost:6006/health

# Acceder a la UI de Phoenix
open http://localhost:6006
```

## Configuraci√≥n

### Variables de Entorno

Agrega las siguientes variables a tu archivo `.env` en la ra√≠z del proyecto:

```env
# Configuraci√≥n de Phoenix
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6006/v1/traces
PHOENIX_GRPC_ENDPOINT=localhost:4317

# Configuraciones de Instrumentaci√≥n
INSTRUMENT_OPENAI=true
INSTRUMENT_GEMINI=true
INSTRUMENT_LLAMA_INDEX=true

# Opcional: m√©tricas de Prometheus
PHOENIX_PROMETHEUS_ENABLED=true
PHOENIX_PROMETHEUS_PORT=9090
```

### Configuraci√≥n de Docker Compose

El archivo `docker-compose.yml` incluye:

```yaml
services:
  phoenix:
    image: arizephoenix/phoenix:latest
    ports:
      - "6006:6006"  # UI y colector OTLP HTTP
      - "4317:4317"  # Colector OTLP gRPC
      - "9090:9090"  # M√©tricas de Prometheus (opcional)
    environment:
      - PHOENIX_WORKING_DIR=/mnt/data
    volumes:
      - phoenix_data:/mnt/data
    env_file:
      - ../../.env
```

## Integraci√≥n con API RAG

### 1. Instalar Paquete Python de Phoenix

```bash
# Agregar a tu pyproject.toml
phoenix = "^4.0.0"
```

### 2. Instrumentaci√≥n B√°sica

```python
# En tu servicio RAG
import phoenix as px
from phoenix.trace import trace

class RAGService:
    @trace
    def answer_question(self, question: str):
        # Tu c√≥digo RAG existente
        # Phoenix capturar√° autom√°ticamente las m√©tricas
        pass
```

### 3. Instrumentaci√≥n Avanzada

```python
# Trazado personalizado para operaciones espec√≠ficas
from phoenix.trace import trace, set_attributes

@trace
def retrieve_documents(self, query: str):
    with trace("embedding_generation"):
        embedding = self.embedding_service.generate_embedding(query)

    with trace("vector_search"):
        results = self.qdrant_service.search(embedding)

    set_attributes({
        "query_length": len(query),
        "results_count": len(results),
        "search_time": time.time() - start_time
    })

    return results
```

## Caracter√≠sticas Avanzadas de Tracing

El sistema de procesamiento de leyes incluye caracter√≠sticas avanzadas de tracing en Phoenix para observabilidad integral:

### Context Managers vs Decoradores

El sistema usa **context managers** en lugar de decoradores para mejor control y tracing granular:

```python
from opentelemetry.trace import SpanKind

# Usando context manager para spans personalizados
with phoenix_span("nombre_operacion", SpanKind.INTERNAL, {"param": "valor"}):
    # Tu c√≥digo de operaci√≥n aqu√≠
    pass
```

### Agrupaci√≥n Autom√°tica de Sesiones

Todos los spans de una sola ejecuci√≥n se agrupan autom√°ticamente bajo una sesi√≥n con identificadores √∫nicos.

## Gesti√≥n de Sesiones

El sistema implementa gesti√≥n autom√°tica de sesiones para agrupar todos los spans de una sola ejecuci√≥n:

### Caracter√≠sticas de Sesi√≥n

- **ID de Sesi√≥n √önico**: Cada ejecuci√≥n obtiene un UUID para identificaci√≥n
- **Agrupaci√≥n Autom√°tica**: Todos los spans se agrupan bajo un span de sesi√≥n ra√≠z
- **Atributos de Sesi√≥n**: Cada span incluye informaci√≥n de sesi√≥n
- **Seguimiento de Duraci√≥n**: El tiempo total de ejecuci√≥n se rastrea a nivel de sesi√≥n

### Estructura de Sesi√≥n

```text
execution_session (SERVER) üîµ [SESI√ìN RA√çZ]
‚îú‚îÄ‚îÄ session.id: "550e8400-e29b-41d4-a716-446655440000"
‚îú‚îÄ‚îÄ session.start_time: "2024-01-15T10:30:00.123456"
‚îú‚îÄ‚îÄ session.type: "law_processing"
‚îú‚îÄ‚îÄ session.version: "1.0"
‚îÇ
‚îî‚îÄ‚îÄ main_process (SERVER) üîµ [HIJO DE SESI√ìN]
    ‚îú‚îÄ‚îÄ session.id: "550e8400-e29b-41d4-a716-446655440000"
    ‚îú‚îÄ‚îÄ execution.timestamp: "2024-01-15T10:30:00.234567"
    ‚îÇ
    ‚îî‚îÄ‚îÄ Todos los spans de operaci√≥n con atributo session.id
```

### Beneficios de Sesi√≥n

1. **Agrupaci√≥n Visual**: Todos los spans de una ejecuci√≥n aparecen agrupados en Phoenix
2. **Filtrado F√°cil**: Filtrar por `session.id` para ver ejecuciones espec√≠ficas
3. **An√°lisis de Rendimiento**: Comparar diferentes ejecuciones f√°cilmente
4. **Trazabilidad Completa**: Rastrear el ciclo de vida completo de cada ejecuci√≥n

### Usando Sesiones en Phoenix

**Filtrar por Sesi√≥n:**

```text
session.id = "550e8400-e29b-41d4-a716-446655440000"
```

**Ver Duraci√≥n de Sesi√≥n:**

- El span ra√≠z `execution_session` muestra el tiempo total de ejecuci√≥n
- Comparar duraciones entre diferentes ejecuciones

## Tipos de Spans y Categorizaci√≥n

El sistema usa Span Kinds de OpenTelemetry para mejor visualizaci√≥n y categorizaci√≥n:

### Tipos de Span Kind

#### üîµ **SpanKind.SERVER**

**Prop√≥sito**: Operaciones principales que coordinan otras operaciones

- `main_process` - Proceso principal de la aplicaci√≥n
- `process_law_local` - Procesamiento local completo
- `process_law_gcs` - Procesamiento GCS completo

#### üü¢ **SpanKind.CLIENT**

**Prop√≥sito**: Operaciones que realizan llamadas externas

- `download_law_page` - Descarga desde URL externa

#### üü° **SpanKind.PRODUCER**

**Prop√≥sito**: Operaciones que env√≠an datos a sistemas externos

- `save_parsed_json_gcs` - Guardar en Google Cloud Storage
- `upload_file_to_gcs` - Subir archivos a GCS

#### ‚ö™ **SpanKind.INTERNAL**

**Prop√≥sito**: Operaciones de procesamiento interno de datos

- `extract_metadata` - Extraer metadatos de la ley
- `extract_articles` - Segmentar art√≠culos
- `parse_law_text` - Procesar texto completo
- `extract_text_from_html` - Extraer texto limpio del HTML
- `save_parsed_json_local` - Guardar archivos localmente

### Beneficios de Span Kinds

1. **Mejor Visualizaci√≥n**: Diferentes iconos y colores para cada tipo de operaci√≥n
2. **Categorizaci√≥n Clara**: Identificaci√≥n f√°cil de tipos de operaci√≥n
3. **An√°lisis de Rendimiento**: Identificar d√≥nde se gastan recursos por tipo
4. **Debugging Mejorado**: Identificaci√≥n m√°s f√°cil de problemas
5. **M√©tricas Espec√≠ficas por Tipo**: Generar m√©tricas por tipo de operaci√≥n

### Jerarqu√≠a de Spans

```text
main_process (SERVER) üîµ
‚îú‚îÄ‚îÄ process_law_local/process_law_gcs (SERVER) üîµ
    ‚îú‚îÄ‚îÄ download_law_page (CLIENT) üü¢
    ‚îú‚îÄ‚îÄ extract_text_from_html (INTERNAL) ‚ö™
    ‚îú‚îÄ‚îÄ parse_law_text (INTERNAL) ‚ö™
    ‚îÇ   ‚îú‚îÄ‚îÄ extract_metadata (INTERNAL) ‚ö™
    ‚îÇ   ‚îî‚îÄ‚îÄ extract_articles (INTERNAL) ‚ö™
    ‚îú‚îÄ‚îÄ save_parsed_json_local (INTERNAL) ‚ö™ [modo local]
    ‚îú‚îÄ‚îÄ upload_file_to_gcs (PRODUCER) üü° [modo GCS]
    ‚îî‚îÄ‚îÄ save_parsed_json_gcs (PRODUCER) üü° [modo GCS]
```

### Atributos por Tipo de Span

**Spans CLIENT:**

- `url` - URL de llamada externa
- `output_path` - Ruta de salida local

**Spans PRODUCER:**

- `bucket_name` - Nombre del bucket de GCS
- `filename` - Nombre del archivo
- `articles_count` - N√∫mero de art√≠culos procesados

**Spans INTERNAL:**

- `lines_count` - N√∫mero de l√≠neas procesadas
- `text_length` - Longitud del texto
- `html_path` - Ruta del archivo HTML
- `articles_count` - N√∫mero de art√≠culos extra√≠dos

**Spans SERVER:**

- `mode` - Modo de operaci√≥n (local/gcs)
- `url` - URL de la ley
- `bucket_name` - Nombre del bucket (solo modo GCS)
- `raw_filename` - Nombre del archivo HTML
- `processed_filename` - Nombre del archivo JSON
- `output_root` - Directorio ra√≠z de salida (solo modo local)
- `use_local_credentials` - Usar credenciales locales (solo modo GCS)

## Caracter√≠sticas de Monitoreo

### 1. An√°lisis de Trazas

Phoenix proporciona trazas detalladas mostrando:

- Flujo de solicitudes a trav√©s del pipeline RAG
- Tiempo gastado en cada componente
- Uso de tokens y costos
- Tasas de error y excepciones

### 2. M√©tricas de Rendimiento

Rastrea indicadores clave de rendimiento:

- **Tiempo de Respuesta**: Tiempo de procesamiento de solicitudes de extremo a extremo
- **Uso de Tokens**: Tokens consumidos por solicitud
- **Throughput**: Solicitudes por minuto
- **Tasa de Error**: Porcentaje de solicitudes fallidas

### 3. Monitoreo de LLM

Monitorea proveedores de LLM:

- **OpenAI**: Llamadas API, uso de tokens, costos
- **Google Gemini**: Llamadas API, uso de tokens, costos
- **Rendimiento del Modelo**: Calidad y consistencia de respuestas

### 4. M√©tricas de Evaluaci√≥n

Rastrea la calidad del sistema RAG:

- **Precisi√≥n de Recuperaci√≥n**: Relevancia de documentos recuperados
- **Calidad de Generaci√≥n**: Precisi√≥n y coherencia de respuestas
- **Efectividad de Reranking**: Impacto del reranking en resultados

## Despliegue en Producci√≥n

### Opci√≥n 1: Phoenix Cloud (Recomendado)

Para producci√≥n, usa Phoenix Cloud para evitar sobrecarga de infraestructura:

1. **Reg√≠strate** en [Phoenix Cloud](https://arize.com/phoenix)
2. **Obt√©n clave API** de tu dashboard
3. **Actualiza variables de entorno**:

```env
PHOENIX_COLLECTOR_ENDPOINT=https://your-instance.phoenix.arize.com/v1/traces
PHOENIX_API_KEY=tu_clave_api_aqui
```

### Opci√≥n 2: Auto-hospedado

Para despliegue auto-hospedado, consulta la [documentaci√≥n de Phoenix](https://arize.com/docs/phoenix/self-hosting/).

## Soluci√≥n de Problemas

### Problemas Comunes

#### Phoenix No Inicia

```bash
# Verificar estado de Docker
docker info

# Verificar disponibilidad de puertos
netstat -tulpn | grep :6006

# Reiniciar Phoenix
docker-compose down
docker-compose up -d
```

#### No Aparecen Trazas

1. **Verificar variables de entorno**:

   ```bash
   echo $PHOENIX_COLLECTOR_ENDPOINT
   ```

2. **Verificar instrumentaci√≥n**:

   ```python
   import phoenix as px
   print(px.get_tracer())
   ```

3. **Verificar conectividad de red**:

   ```bash
   curl http://localhost:6006/health
   ```

#### Alto Uso de Memoria

```bash
# Monitorear uso de recursos
docker stats phoenix

# Ajustar l√≠mites de memoria en docker-compose.yml
services:
  phoenix:
    mem_limit: 2g
```

### Logs y Depuraci√≥n

```bash
# Ver logs de Phoenix
docker-compose logs phoenix

# Seguir logs en tiempo real
docker-compose logs -f phoenix

# Verificar logs espec√≠ficos del servicio
docker-compose logs phoenix | grep ERROR
```

## Mejores Pr√°cticas

1. **Comenzar con Desarrollo Local**: Usa Phoenix local para desarrollo y pruebas
2. **Usar Phoenix Cloud para Producci√≥n**: Evita sobrecarga de infraestructura
3. **Instrumentar Operaciones Clave**: Enf√≥cate en rutas cr√≠ticas en tu pipeline RAG
4. **Monitorear Uso de Recursos**: Mant√©n un ojo en el uso de memoria y CPU
5. **Configurar Alertas**: Configura alertas para m√©tricas cr√≠ticas
6. **Limpieza Regular**: Limpia trazas antiguas para gestionar almacenamiento
